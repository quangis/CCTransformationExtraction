# Name:        Interpreting Geo-analytical Questions as core concept transformations
# Purpose:     Python script for identifying placenames, entities, and core concepts in each geo-analytical question,
#              then extracting core concept transformations from parser trees generated by a Antlr4 grammar-GenAnQu.g4.

import json
import re
import numpy
# [X] import nlp packages for placename and entities recognition
from spacy.lang.en import English
import en_core_web_sm
from spacy.matcher import PhraseMatcher
import nltk
import nltk.tokenize as nt
from allennlp.predictors.predictor import Predictor  # For using ELMo-based NER & Fine Grained NER
# import allennlp_models.tagging
from word2number import w2n
# [X] import antlr4 grammar
from antlr4 import *
from Grammar.GeoAnQuLexer import GeoAnQuLexer
from Grammar.GeoAnQuParser import GeoAnQuParser
from antlr4.tree.Trees import Trees


# from antlr4.error.ErrorListener import ErrorListener


# [X]  customized a list of stopwords
class CustomEnglishDefaults(English.Defaults):
    # stop_words = set(["is", "are", "was", "were", "do", "does", "did", "have", "had"])
    stop_words = {"do", "did", "does", "a", "an", "the", "their", 'his', 'her', 'my'}


class CustomEnglish(English):
    lang = "custom_en"
    Defaults = CustomEnglishDefaults


# [X] Raise exception for errors in parsing questions, such as token recognition error.
# class MyErrorListener(ErrorListener):
#     def __init__(self):
#         super(MyErrorListener, self).__init__()
#
#     def syntaxError(self, recognizer, offendingSymbol, line, column, msg, e):
#         raise Exception()
#
#     def reportAmbiguity(self, recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs):
#         raise Exception()
#
#     def reportAttemptingFullContext(self, recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs):
#         raise Exception()
#
#     def reportContextSensitivity(self, recognizer, dfa, startIndex, stopIndex, prediction, configs):
#         raise Exception()


class BracketMatch:
    def __init__(self, refstr, parent=None, start=-1, end=-1):
        self.parent = parent
        self.start = start
        self.end = end
        self.refstr = refstr
        self.nested_matches = []

    def __str__(self):
        cur_index = self.start + 1
        result = ""
        if self.start == -1 or self.end == -1:
            return ""
        for child_match in self.nested_matches:
            if child_match.start != -1 and child_match.end != -1:
                result += self.refstr[cur_index:child_match.start]
                cur_index = child_match.end + 1
            else:
                continue
        result += self.refstr[cur_index:self.end]
        return result


def is_left_inside(string, list):
    cur_list = []
    for l in list:
        if l.lower().strip().startswith(string):
            cur_list.append(l)
    return cur_list


# [X] Convert numeric words into digit numbers
# Input sentence(string): 'What is average network distance for three thousand and five people to
# two hundred and twelve closest primary schools'.
# Output sentence(string): 'What is average network distance for 3005 people to 212 closest primary schools'.
# except for 'five star hotels'
def word2num(sentence):
    try:
        if 'five star' not in sentence:
            cur_doc = nlp(sentence)
            numWords = ''
            numDig = ''
            for cur_i in range(0, len(cur_doc)):
                if cur_doc[cur_i].pos_ == 'NUM':
                    numWords = numWords + ' ' + cur_doc[cur_i].text
                    cur_i += 1
                elif cur_doc[cur_i].text == 'and' and cur_doc[cur_i - 1].pos_ == 'NUM':
                    numWords = numWords + ' and'
                    cur_i += 1
                elif numWords and not cur_doc[cur_i].pos_ == 'NUM':
                    numDig = w2n.word_to_num(numWords.strip())
                    # print(numWords)
                    # print(numDig)
                    sentence = sentence.replace(numWords.strip(), str(numDig))
                    numWords = ''
    except:
        return sentence

    return sentence


# [X] Identify Place names(e.g., ) in questions
# input string sentence:
# 'What buildings are within 1 minute of driving time from a fire station for
# Multifunctional Urban Area in Fort Worth in US
# output tuple:
# (['Multifunctional Urban Area', 'Fort Worth', 'US'],
# 'What buildings are within 1 minute of driving time from a fire station
# for each PlaceName0 in PlaceName1 in PlaceName3')
def place_ner(sentence):
    # predictorELMo = Predictor.from_path(
    #     "https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz")
    pred = predictorELMo.predict(sentence)

    PlaceName = []
    loc = 0
    for i in range(0, len(pred['tags'])):
        # place name is a single word, such as Utrecht
        # unsolved question: Which urban areas are within 150 miles of the Ogallala aquifer, have precipitation lower than 10 inches, and intersect with the irrigation regions in Ogallala (High Plains) Aquifer, US
        if pred['tags'][i] == 'U-LOC' or pred['tags'][i] == 'U-PER':
            if not pred['words'][i] == 'PC4':
                PlaceName.append(pred['words'][i])
                sentence = sentence.replace(pred['words'][i], 'PlaceName' + str(loc))
                loc += 1
        elif pred['tags'][i] == 'B-LOC':  # When place name is a phrase, such as Happy Valley
            place = pred['words'][i]
        elif pred['tags'][i] == 'I-LOC' or pred['tags'][i] == 'L-LOC':
            place = place + ' ' + pred['words'][i]
            if i + 1 == len(pred['tags']):
                PlaceName.append(place)
                sentence = sentence.replace(place, 'PlaceName' + str(loc))
                place = ''
            elif pred['tags'][i + 1] == 'O':  # 'O' not a place name
                PlaceName.append(place)
                sentence = sentence.replace(place, 'PlaceName' + str(loc))
                loc += 1
                place = ''

    #  allennlp fail to capture Oleander as city name
    cur_words2 = sentence.strip().split(' ')
    if 'Oleander' in cur_words2:
        sentence = sentence.replace('Oleander', 'PlaceName' + str(len(PlaceName)))
        PlaceName.append('Oleander')

    # Solve place name + place type, such as PlaceName0 area(PC4 area) -> PlaceName0(PC4 area)...
    cur_words = sentence.strip().split(' ')
    for i in range(0, len(cur_words)):
        if cur_words[i].startswith('PlaceName'):
            if i + 1 < len(cur_words):
                if not len(is_left_inside(cur_words[i + 1],
                                          pt_set)) == 0:  # PlaceName0 ski resort(Happy Valley ski resort) -> PlaceName0
                    if i + 2 < len(cur_words):
                        cur_pt = cur_words[i + 1] + ' ' + cur_words[i + 2]
                        if cur_pt in is_left_inside(cur_words[i + 1], pt_set):
                            cur_index = int(cur_words[i][9:])  # PlaceName0 -> 0
                            PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_pt
                            sentence = sentence.replace(' ' + cur_pt, '')
                        elif i + 3 < len(cur_words):
                            cur_pt = ' '.join(cur_words[i + 1:i + 4])
                            if cur_pt in is_left_inside(cur_words[i + 1], pt_set):
                                cur_index = int(cur_words[i][9:])
                                PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_pt
                                sentence = sentence.replace(' ' + cur_pt, '')
                            elif cur_words[i + 1] in pt_set:
                                cur_index = int(cur_words[i][9:])
                                PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_words[i + 1]
                                sentence = sentence.replace(' '.join(cur_words[i:i + 2]), cur_words[i])
                elif cur_words[i + 1] in pt_set:  # PlaceName0(Happy Valley) resort -> PlaceName0(Happy Valley resort)
                    cur_index = int(cur_words[i][9:])  # PlaceName0 -> 0
                    PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_words[i + 1]
                    sentence = sentence.replace(' '.join(cur_words[i:i + 2]), cur_words[i])

    # print(sentence)
    # print(PlaceName)
    return PlaceName, sentence


# [X] Identify Date, Time, Quantity, Percent
# input string sentence:
# 'What buildings are within 1 minute, 2 minutes and 3 minutes of driving time from 3 fire stations that are
# within 60 meters of rivers and located at areas that has slope larger than 10 percent for each PlaceName1 in
# PlaceName2 between 1990 and 2000'
# output tuple:
# ({'Time': [1 minute, 2 minutes, 3 minutes], 'Quantity': [60 meters],
# 'Percent': [larger than 10 percent], 'Date': [between 1990 and 2000]},
# 'What buildings are within ETime0, ETime1, and ETime2 of driving time from 3 fire stations that are within
# EQuantity0 of rivers and located at areas that has slope EPercent1 for each PlaceName0 in PlaceName1 EDate0')
def entity_ner(sentence):
    entities = []
    enti_dict = {}
    Date = []
    Time = []
    Quantity = []
    Percent = []

    cur_sen = ''
    if 'each' in sentence:  # {'Quantity': [each 50 square km]} -> {'Quantity': [50 square km]}
        cur_sen = sentence.replace(' each', '')
    else:
        cur_sen = sentence

    cur_doc = nlp(cur_sen)
    # entities = [(i.text, i.label_) for i in cur_doc.ents]
    # e.g., tuple entities = [(1 minute, 'TIME'), (between 1990 and 2000, 'DATE')]
    # remove compareR from entities. [('larger than 15 percent', 'PERCENT')] -> [('15 percent', 'PERCENT')]
    for i in cur_doc.ents:
        compBool = [word in i.text for word in compR]
        if True in compBool:
            tin = compBool.index(True)
            en_text = i.text.replace(compR[tin] + ' ', '')
            entities.append((en_text, i.label_))
        else:
            ilist = i.text.split(' ')
            if ilist[-1] == 'by':
                entities.append((i.text.replace(' by', ''), i.label_))
            else:
                entities.append((i.text, i.label_))

    # print(entities)

    D_loc = 0
    T_loc = 0
    Q_loc = 0
    P_loc = 0

    cardinal_sen = sentence.strip().split(' ')
    for i in range(0, len(entities)):
        if entities[i][1] == 'TIME':
            Time.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'ETime' + str(T_loc))
            T_loc += 1
        elif entities[i][1] == 'QUANTITY':
            Quantity.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif entities[i][1] == 'CARDINAL' and entities[i][0].isnumeric() and cardinal_sen.index(
                entities[i][0]) + 1 < len(cardinal_sen) and \
                cardinal_sen[cardinal_sen.index(entities[i][0]) + 1] in units:  # 70 db
            quan_words = entities[i][0] + ' ' + cardinal_sen[cardinal_sen.index(entities[i][0]) + 1]
            Quantity.append(quan_words)
            sentence = sentence.replace(quan_words, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif entities[i][1] == 'CARDINAL' and any(
                x in entities[i][0].split(' ') for x in units):  # [('between 700 and 2000 meters', 'CARDINAL')]
            Quantity.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif entities[i][1] == 'PERCENT':
            Percent.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EPercent' + str(P_loc))
            P_loc += 1
        elif entities[i][1] == 'DATE' and not entities[i][0] == 'annual' and not entities[i][0] == 'monthly' \
                and not entities[i][0].startswith('PlaceName'):
            Date.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EDate' + str(D_loc))
            D_loc += 1

    cur_w = sentence.strip().split(' ')
    cur_quan = ''
    for w in cur_w:
        if w.startswith('meter') or w.startswith('millimeter'):
            cur_quan = cur_w[cur_w.index(w) - 1] + ' ' + w
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w.isnumeric() and cur_w.index(w) < len(cur_w) - 3 and cur_w[cur_w.index(w) + 1] == 'per' and cur_w[
            cur_w.index(w) + 2] == 'square' and cur_w[cur_w.index(w) + 3].startswith(
            'kilometer'):  # 300 per square kilometer
            cur_quan = w + ' per square ' + cur_w[cur_w.index(w) + 3]
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w == 'per' and cur_w.index(w) < len(cur_w) - 3 and cur_w[cur_w.index(w) - 1].isnumeric() and cur_w[
            cur_w.index(w) + 1].isnumeric():  # 500 per 1000000 people
            cur_quan = ' '.join(cur_w[cur_w.index(w) - 1: cur_w.index(w) + 3])
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w.isnumeric() and cur_w[int(cur_w.index(w) - 1)] == 'over' and cur_w[
            int(cur_w.index(w) - 2)] in humanWords:
            Date.append('over ' + w)
            sentence = sentence.replace('over ' + w, 'EDate' + str(D_loc))
            D_loc += 1
        elif w.isnumeric() and cur_w[int(cur_w.index(w) - 1)] == 'than' and cur_w[
            int(cur_w.index(w) - 3)] in humanWords:
            cur_date = ' '.join(cur_w[cur_w.index(w) - 2: cur_w.index(w) + 1])
            Date.append(cur_date)
            sentence = sentence.replace(cur_date, 'EDate' + str(D_loc))
            D_loc += 1

    cur_words = sentence.strip().split(' ')
    if not len(Time) == 0:
        enti_dict['time'] = Time
    if not len(Quantity) == 0:
        for w in cur_words:
            if w.startswith('EQuantity'):
                i = cur_words.index(w)
                if cur_words[i - 1] == 'by' and cur_words[
                    i - 2].isnumeric():  # 2 by Quantity0(2 km) grid cell -> Quantity0 grid cell
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 2:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 2:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'from':  # from Quantity0(60 to 600 meters) -> Quantity0
                    Quantity[int(w[9])] = 'from ' + Quantity[int(w[9])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'to' and cur_words[i - 2].isnumeric() and cur_words[
                    i - 3] == 'from':  # from 300 to Quantity0(900 meters) -> Quantity0
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 3:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'and' and cur_words[i - 2].isnumeric() and cur_words[
                    i - 3] == 'between':  # between 700 and Quantity0(2000 meters) -> Quantity0
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 3:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i + 1] == 'per' and cur_words[i + 2] == 'second':
                    Quantity[int(w[9])] = Quantity[int(w[9])] + ' ' + ' '.join(cur_words[i + 1:i + 3])
                else:
                    enti_dict['quantity'] = Quantity
    if not len(Percent) == 0:
        enti_dict['percent'] = Percent
    if not len(Date) == 0:
        for w in cur_words:
            if w.startswith('EDate'):
                i = cur_words.index(w)
                if cur_words[i - 2].isnumeric() and cur_words[i - 1] == 'to':  # from 2000 to Date0 -> Date0
                    Date[int(w[5])] = ' '.join(cur_words[i - 3:i]) + ' ' + Date[int(w[5])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['date'] = Date
                elif i + 2 < len(cur_words) and cur_words[i + 2].isnumeric() and cur_words[
                    i + 1] == 'to':  # from Date0 to 1994
                    Date[int(w[5])] = cur_words[i - 1] + ' ' + Date[int(w[5])] + ' ' + ' '.join(cur_words[i + 1:i + 3])
                    sentence = sentence.replace(cur_words[i - 1] + ' ' + w + ' ' + ' '.join(cur_words[i + 1:i + 3]), w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and i + 1 == len(cur_words):  # from Date0 (1997 to 2004)
                    Date[int(w[5])] = 'from ' + Date[int(w[5])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and i + 1 < len(cur_words) and not cur_words[
                                                                                       i + 1] == 'to':  # from Date0 (1997 to 2004) in Utrecht
                    Date[int(w[5])] = 'from ' + Date[int(w[5])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and cur_words[i + 1] == 'to' and cur_words[i + 2].startswith(
                        'Date') and i + 2 < len(cur_words):  # from date0 to date1 -> date0
                    Date[int(w[5])] = 'from ' + Date[int(w[5])] + ' to ' + Date[int(cur_words[i + 2][5])]
                    Date.remove(Date[int(cur_words[i + 2][5])])
                    sentence = sentence.replace('from ' + w + ' to ' + cur_words[i + 2], w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'over':  # over 65 years
                    Date[int(w[5])] = 'over ' + Date[int(w[5])]
                    sentence = sentence.replace('over ' + w, w)
                    enti_dict['date'] = Date
                else:
                    enti_dict['date'] = Date

    # print(enti_dict)
    # print(sentence)

    return enti_dict, sentence


# Read Core concepts.txt into a dictionary.
def load_ccdict(filePath):
    coreCon = {}
    text = []
    tag = []
    meaLevel = []  # measurement level
    with open(filePath, encoding="utf-8") as coreConcepts:
        for line in coreConcepts:
            cur = line.strip().split('\t')
            text.append(cur[0].lower())
            tag.append(cur[1].lower())
            if len(cur) == 3:
                meaLevel.append(cur[2].lower())
            else:
                meaLevel.append('NULL')
    coreCon['text'] = text
    coreCon['tag'] = tag
    coreCon['measureLevel'] = meaLevel

    return coreCon


# [X] Clean noun_phrases after noun chunks recognition, remove superlatives and comparatives, placenames, entities...
def noun_phrases_correct(noun_phrases_list):
    noun_phrases_CleanList = []

    for cur_noun in noun_phrases_list:
        if 'each' in cur_noun:
            cur_noun = cur_noun.replace('each ', '')
        if cur_noun in cn:
            noun_phrases_CleanList.append(cur_noun)
            # print('noun_phrases_CleanList:', noun_phrases_CleanList)
        else:
            cur_p = nt.sent_tokenize(cur_noun)
            tokenized_sen = [nt.word_tokenize(p) for p in cur_p]  # [['nearest', 'supermarket']]
            if (any('area' in m for m in tokenized_sen[0]) and not any(
                    'equantity' in n for n in tokenized_sen[0])) or not any(
                    'area' in m for m in tokenized_sen[0]):  # remove 'equantity0 area of road'
                cur_pos = [nltk.pos_tag(cur_sen) for cur_sen in tokenized_sen][
                    0]  # [('nearest', 'JJS'), ('supermarket', 'NN')]
                for e in cur_pos:
                    pos.append(e)
                res = [sub[0] for sub in cur_pos if
                       ('JJS' in sub[1] and not sub[0] == 'west') or 'JJR' in sub[1] or 'RBS' in sub[1] or 'RBR' in sub[
                           1]]  # ['longest', 'more', 'most']

                if 'most' in res or 'more' in res:  # most intense, also remove intense; more than, also remove than
                    mostIndex = [cur_pos.index(sub) for sub in cur_pos if sub[0] == 'most' or sub[0] == 'more']
                    nextIndex = mostIndex[0] + 1
                    if cur_pos[nextIndex][1] == 'JJ' or cur_pos[nextIndex][0] == 'than':
                        res.append(cur_pos[nextIndex][0])

                nounStr_Clean = [ele for ele in tokenized_sen[0] if ele not in res and ele.lower() not in removeWords
                                 and not ele.startswith('placename') and not ele.startswith('edate') and not
                                 ele.startswith('equantity') and not ele.startswith('etime') and not ele.startswith(
                    'epercent')
                                 and not ele.startswith(
                    'outside') and not ele.isnumeric() and not ele == ',' or ele == '911']
                # print('nounStr_Clean:', nounStr_Clean)

                cur_noun_Clean = ' '.join(text for text in nounStr_Clean).strip()
                # print('cur_noun_Clean:', cur_noun_Clean)

                # [X] remove 'areas' in 'what areas', 'many' in 'how many'...'how many buildings'->'buildings'
                if cur_noun_Clean.startswith('areas'):
                    cur_noun_Clean = cur_noun_Clean.replace('areas', '')
                # if cur_noun_Clean.startswith('area'):
                #     cur_noun_Clean = cur_noun_Clean.replace('area', '')
                if cur_noun_Clean.startswith('many'):
                    cur_noun_Clean = cur_noun_Clean.replace('many', '')
                if cur_noun_Clean.startswith('much'):
                    cur_noun_Clean = cur_noun_Clean.replace('much', '')

                if cur_noun_Clean:
                    noun_phrases_CleanList.append(cur_noun_Clean.strip())

    return noun_phrases_CleanList


# [X] Identify Core concepts: field, object, event, network, contentAmount, coverageAmount, conProportion, proportion
# input string sentence: What is number of crime cases for each police district in PlaceName0 in Date0
# output string sentence: what is conamount0 era of event0 for each object0 in placename0 in date0
# output tuple: {'Object': ['police district'], 'Event': ['crime cases'], 'ConAmount': ['number']}
def core_concept_match(sentence):
    # [X] Noun chunks recognition, and remove Entity tags from detected noun chunks
    # cur_que = pre_cc_ner(sentence)
    cur_sen = sentence
    cur_doc = nlp(cur_sen)
    cur_matches = matcher(cur_doc)
    match_phrases = [cur_doc[start: end].text for mat_id, start, end in cur_matches]
    for cur_ph in match_phrases:
        cur_sen = cur_sen.replace(cur_ph + ' ', '')
    cur_doc2 = nlp(cur_sen)
    noun_list = [noun.text for noun in cur_doc2.noun_chunks]
    if not len(match_phrases) == 0:
        for cur_phr in match_phrases:
            noun_list.append(cur_phr)
    # print('noun_list:', noun_list)

    noun_list_Clean = noun_phrases_correct(noun_list)
    # print('noun_list_Clean:', noun_list_Clean)

    # [X] Identify core concepts from noun chunks
    coreConcept_dect = {}
    field = []
    object = []
    objectQuality = []
    event = []
    eventQuality = []
    network = []
    networkQuality = []
    quality = []
    conAmount = []
    objConAmount = []
    eveConAmount = []
    covAmount = []
    conConPro = []
    objConobjConPro = []
    eveConobjConPro = []
    conCovPro = []
    objConobjCovPro = []
    eveConobjCovPro = []
    covPro = []
    proportion = []

    fie_loc = 0
    obj_loc = 0
    objQ_loc = 0
    eve_loc = 0
    eveQ_loc = 0
    net_loc = 0
    netQ_loc = 0
    qua_loc = 0
    conA_loc = 0
    objConA_loc = 0
    eveConA_loc = 0
    covA_loc = 0
    objConobjConP_loc = 0
    eveconobjconP_loc = 0
    conconP_loc = 0
    objConobjCovP_loc = 0
    eveConobjCovP_loc = 0
    concovP_loc = 0
    covpro_loc = 0
    pro_loc = 0

    for cur_noun in noun_list_Clean:
        cur_w = cur_noun.split(' ')
        # print('cur_w:', cur_w)
        if cur_noun in coreCon_dict['text'] and not cur_noun == 'population':
            cur_index = coreCon_dict['text'].index(cur_noun)
            if coreCon_dict['tag'][cur_index] == 'field':
                field.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'field' + str(fie_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                fie_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object':
                object.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'object' + str(obj_loc))
                obj_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object quality':
                objectQuality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objectquality' + str(objQ_loc) + ' ' +
                                            coreCon_dict['measureLevel'][
                                                cur_index])
                objQ_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event':
                event.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'event' + str(eve_loc))
                eve_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event quality':
                eventQuality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveQ_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'network':
                cur_ns = cur_noun.split(' ')[0]
                cur_i = [x for x, y in enumerate(pos) if y[0] == cur_ns]
                if len(cur_i) >= 1 and (pos[cur_i[0] - 1][1] == 'JJS' or pos[cur_i[0] - 1][1] == 'RBS'):
                    cur_np = pos[cur_i[0] - 1][0] + ' ' + cur_noun
                    network.append(cur_np)
                    sentence = sentence.lower().replace(cur_np, 'network' + str(net_loc))
                    net_loc += 1
                else:
                    network.append(cur_noun)
                    sentence = sentence.lower().replace(cur_noun, 'network' + str(net_loc))
                    net_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'network quality':
                networkQuality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'networkquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                netQ_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'quality':
                quality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'quality' + str(qua_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                qua_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'covamount':
                covAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'covamount' + str(covA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                covA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'conamount':
                conAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'conamount' + str(conA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                conA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object conamount':
                objConAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconamount' + str(objConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event conamount':
                eveConAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconamount' + str(eveConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveConA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'objconobjconpro':
                objConobjConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconobjconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConobjConP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'eveconobjconpro':
                eveConobjConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconobjconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveconobjconP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'conconpro':
                conConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'conconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                conconP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'objconobjcovpro':
                objConobjCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconobjcovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConobjCovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'eveconobjcovpro':
                eveConobjCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconobjcovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveConobjCovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'concovpro':
                conCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'concovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                concovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'covpro':
                covPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'covpro' + str(covpro_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                covpro_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'proportion':
                proportion.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'proportion' + str(pro_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                pro_loc += 1
        elif cur_w[0] == 'average' or cur_w[0] == 'median' or cur_w[0] == 'total':  # average Euclidean distance
            cur_r = ' '.join(cur_w[1:])  # 'Euclidean' 'distance' -> 'Euclidean distance'
            if cur_r in coreCon_dict['text']:
                cur_in = coreCon_dict['text'].index(cur_r)
                if coreCon_dict['tag'][cur_in] == 'field':
                    field.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'field' + str(fie_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
                    fie_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object':
                    object.append(cur_r)
                    sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
                    obj_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object quality':
                    objectQuality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'objectquality' + str(objQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    objQ_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'event':
                    event.append(cur_r)
                    sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
                    eve_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'event quality':
                    eventQuality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    eveQ_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'network':
                    network.append(cur_r)
                    sentence = sentence.lower().replace(cur_r, 'network' + str(net_loc))
                    net_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'network quality':
                    networkQuality.append(cur_r)
                    sentence = sentence.lower().replace(cur_r, 'networkquality' + str(netQ_loc) + ' ' +
                                                        coreCon_dict['measureLevel'][
                                                            cur_in])
                    netQ_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'quality':
                    quality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'quality' + str(qua_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
                    qua_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'covamount':
                    covAmount.append(cur_r)
                    sentence = sentence.replace(cur_r, 'covamount' + str(covA_loc) + ' ' + coreCon_dict['measureLevel'][
                        cur_in])
                    covA_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'conamount':
                    conAmount.append(cur_r)
                    sentence = sentence.replace(cur_r, 'conamount' + str(conA_loc) + ' ' + coreCon_dict['measureLevel'][
                        cur_in])
                    conA_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object conamount':
                    objConAmount.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'objconamount' + str(objConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    objConA_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'count' or cur_w[len(cur_w) - 1] == 'counts' or cur_w[
        #     len(cur_w) - 1] == 'totals' or cur_w[len(cur_w) - 1] == 'total':  # house totals -> Object ConAmount
        #     conAmount.append(cur_w[len(cur_w) - 1])
        #     sentence = sentence.replace(cur_w[len(cur_w) - 1], 'conamount' + str(conA_loc) + ' era')
        #     conA_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'density':  # household density, tree density
        #     covPro.append('density')
        #     sentence = sentence.replace('density', 'covpro' + str(covpro_loc) + ' ira')
        #     covpro_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 2:len(cur_w)] == ['mortality', 'rate']:
        #     ConConPro.append('mortality rate')
        #     sentence = sentence.replace('mortality rate', 'objconobjconpro' + str(conconP_loc) + ' ira')
        #     conconP_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 2])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             Object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             Event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'rate':
        #     ConConPro.append('rate')
        #     sentence = sentence.replace('rate', 'conconpro' + str(conconP_loc) + ' ira')
        #     conconP_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             Object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'object quality':
        #             ObjectQuality.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'objectquality' + str(objQ_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
        #             objQ_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             Event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event quality':
        #             EventQuality.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])

    if 'population' in sentence:
        objConAmount.append('population')
        sentence = sentence.replace('population', 'objconamount' + str(objConA_loc) + ' ' + 'era')
        objConA_loc += 1

    # [X] 'local road' is network in 'What is the potential accessibility by local road for each 2 by 2 km grid cell
    # in Finland'; 'roads' is object in 'Which roads are intersected with forest areas in UK'
    for cur_noun in noun_list_Clean:
        if cur_noun in networkSet:
            if 'network' in sentence or 'access' in cur_sen or 'connectivity' in cur_sen:
                network.append(cur_noun)
                sentence = sentence.lower().replace(cur_noun, 'network' + str(net_loc))
                net_loc += 1
            else:
                object.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'object' + str(obj_loc))
                obj_loc += 1

    # cur_words = sentence.split(' ')
    # for w in cur_words:  # has 4 object -> has 4 objconAmount
    #     ind = cur_words.index(w)
    #     if w.startswith('object') and not w.startswith('objectquality') and 'network0' not in cur_words and (
    #             cur_words[ind - 2] in amsign or cur_words[ind - 1] in amsign) and not cur_words[ind - 1] == 'from':
    #         objConAmount.append(object[int(w[-1])])
    #         sentence = sentence.replace(w, 'objconamount' + str(len(objConAmount) - 1) + ' era')
    #     elif w.startswith('event') and not w.startswith('eventquality') and 'network0' not in cur_words and (
    #             cur_words[ind - 2] in amsign or cur_words[ind - 1] in amsign) and not cur_words[ind - 1] == 'from':
    #         eveConAmount.append(event[int(w[-1])])
    #         sentence = sentence.replace(w, 'eveconamount' + str(len(eveConAmount) - 1) + ' era')

    if not field == []:
        coreConcept_dect['field'] = field
    if not object == []:
        coreConcept_dect['object'] = object
    if not objectQuality == []:
        coreConcept_dect['objectquality'] = objectQuality
    if not event == []:
        coreConcept_dect['event'] = event
    if not eventQuality == []:
        coreConcept_dect['eventquality'] = eventQuality
    if not network == []:
        coreConcept_dect['network'] = network
    if not networkQuality == []:
        coreConcept_dect['networkquality'] = networkQuality
    if not quality == []:
        coreConcept_dect['quality'] = quality
    if not conAmount == []:
        coreConcept_dect['conamount'] = conAmount
    if not len(objConAmount) == 0:
        coreConcept_dect['objconamount'] = objConAmount
    if not len(eveConAmount) == 0:
        coreConcept_dect['eveconamount'] = eveConAmount
    if not covAmount == []:
        coreConcept_dect['covamount'] = covAmount
    if not conConPro == []:
        coreConcept_dect['conconpro'] = conConPro
    if not objConobjConPro == []:
        coreConcept_dect['objconobjconpro'] = objConobjConPro
    if not eveConobjConPro == []:
        coreConcept_dect['eveconobjconpro'] = eveConobjConPro
    if not conCovPro == []:
        coreConcept_dect['concovpro'] = conCovPro
    if not objConobjCovPro == []:
        coreConcept_dect['objconobjcovpro'] = objConobjCovPro
    if not eveConobjCovPro == []:
        coreConcept_dect['eveconobjcovpro'] = eveConobjCovPro
    if not covPro == []:
        coreConcept_dect['covpro'] = covPro
    if not proportion == []:
        coreConcept_dect['proportion'] = proportion

    # print(coreConcept_dect)
    # print(sentence)

    return coreConcept_dect, sentence.lower()


# [X] Extract parser rules(tags) and text from parserTreeString
def get_text(cur_treeStr):
    nodetextDic = {}
    root = BracketMatch(cur_treeStr)
    cur_match = root
    for i in range(len(cur_treeStr)):
        if '(' == cur_treeStr[i]:
            new_match = BracketMatch(cur_treeStr, cur_match, i)
            cur_match.nested_matches.append(new_match)
            cur_match = new_match
        elif ')' == cur_treeStr[i]:
            cur_match.end = i
            cur_match = cur_match.parent
        else:
            continue
    # Here we built the set of matches, now we must print them
    nodes_list = root.nested_matches
    tag = []
    # So we conduct a BFS to visit and print each match...
    while nodes_list != []:
        node = nodes_list.pop(0)
        nodes_list.extend(node.nested_matches)
        nodeStr = str(node).strip()
        nodetextDic.setdefault('tag', []).append(nodeStr.split()[0])
        nodetextDic.setdefault('text', []).append(' '.join(nodeStr.split()[1:][0:len(nodeStr.split()[1:])]))

    return nodetextDic


# [X]Extract core concept from texts and tags of the parse tree
# Input: {'tag': ['condition', 'boolR', 'extremaR', 'coreC', 'coreC', 'coreC'], 'text': ['of to', 'has', 'highest',
# 'proportion 0 ira', 'object 1', 'objconamount 0 count']}
# Output: {'tag': ['coreC', 'coreC', 'coreC'], 'text': ['proportion 0 ira', 'object 1', 'objconamount 0 count']}
def core_concept_extract(TreeDict):
    cur_TD = {}
    keep_set = {'coreC', 'networkC', 'networkQ', 'location', 'allocation', 'conAm', 'boolField', 'distField',
                'serviceObj', 'aggre', 'compareR'}  # 'extremaR',
    tag_in = [i for i, x in enumerate(TreeDict['tag']) if not x in keep_set]
    cur_TD['tag'] = [TreeDict['tag'][i] for i in range(0, len(TreeDict['tag'])) if i not in tag_in]
    for i in range(0, len(cur_TD['tag'])):
        if cur_TD['tag'][i] == 'boolField' or cur_TD['tag'][i] == 'distField' or cur_TD['tag'][i] == 'serviceObj':
            cur_TD['tag'][i] = cur_TD['tag'][i].lower()
    cur_TD['text'] = [TreeDict['text'][i] for i in range(0, len(TreeDict['text'])) if i not in tag_in]

    # at least 3000 meters from the rivers or Where are the luxury hotels with more than 20 bedrooms {'tag': ['compareR', 'coreC'], 'text': ['more than', 'object 1']}
    if 'compareR' in cur_TD['tag'] and ('boolfield' in cur_TD['tag'] or (
            len(cur_TD['tag']) == 2 and cur_TD['tag'].index('compareR') + 1 < 2 and cur_TD['tag'][
        cur_TD['tag'].index('compareR') + 1] == 'coreC')):
        compR_index = cur_TD['tag'].index('compareR')
        cur_TD['tag'].pop(compR_index)
        cur_TD['text'].pop(compR_index)

    # from origin to the nearest destination, add extreDist(nearest) to cur_TD
    if 'extreDist' in TreeDict['tag'] and (
            'networkC' in TreeDict['tag'] or 'networkQ' in TreeDict['tag']) and 'serviceObj' not in TreeDict['tag']:
        cur_in = [cur_TD['tag'].index(i) for i in TreeDict['tag'] if i.startswith('network')][0]
        cur_TD['tag'].insert(cur_in, 'extreDist')
        cur_TD['text'].insert(cur_in, TreeDict['text'][TreeDict['tag'].index('extreDist')])

    return cur_TD


# [X]Write core concepts in the questions into the designed structure
# Input dictionary: {'tag': ['origin', 'destination', 'networkC', 'serviceObj', 'boolField'],
# 'text': [['object 1', 'hexagonal grids with diameter of 2000 meters'], 'object 0', 'network 0', 'from to', '']}
# Output[0]: [{'type': ['object'], 'id': '0', 'keyword': 'centroid'}, {...}, ...]
# Output[1]:{'tag': ['origin', 'destination', 'networkC', 'serviceObj', 'boolField'],
# 'text': [['object 1', 'hexagonal grids with diameter of equantity 1'], 'object 0', 'network 0', 'from to', ''],
# 'id': [['0', '1'], '2', '3', '4']}
def write_type(coreDict):
    global result
    global core_id
    corety = []
    csign = 0

    #--------new---------
    for cur_tag in coreDict['tag']:
        if cur_tag == 'distfield' or cur_tag == 'location' or cur_tag == 'allocation': #--------new---------
            coreType = {}
            coreType['type'] = cur_tag
            coreType['id'] = str(core_id)
            coreType['keyword'] = ''
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'boolfield' and 'serviceobj' not in coreDict['tag']: #--------new---------
            coreType = {}
            coreType['type'] = cur_tag
            coreType['id'] = str(core_id)
            coreType['keyword'] = ''
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'conAm':
            coreType = {}
            coreType['type'] = 'conamount'
            coreType['id'] = str(core_id)
            # -------new-----
            coreType['keyword'] = 'how many'
            coreType['measureLevel'] = 'count'
            # -------new-----
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'grid' or cur_tag == 'distanceBand':
            coreType = {}
            coreType['type'] = cur_tag
            coreType['id'] = str(core_id)
            coreType['keyword'] = coreDict['text'][coreDict['tag'].index(cur_tag)]
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'aggre':
            coreType = {}
            coreType['type'] = cur_tag
            coreType['id'] = str(core_id)
            curtag_index = coreDict['tag'].index(cur_tag)
            coreType['keyword'] = coreDict['text'][curtag_index]
            if coreDict['tag'][curtag_index - 1] == 'extreDist' and coreDict['text'][curtag_index - 2].split(' ')[
                -1] in measLevel:
                coreType['measureLevel'] = coreDict['text'][curtag_index - 2].split(' ')[-1]
            elif coreDict['text'][curtag_index - 1].split(' ')[-1] in measLevel:
                coreType['measureLevel'] = coreDict['text'][curtag_index - 1].split(' ')[-1]
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'networkC':
            # read network keywords
            coreType = {}
            nts = coreDict['text'][coreDict['tag'].index('networkC')].split(' ')
            coreType['type'] = nts[0]
            coreType['id'] = str(core_id)
            coreType['keyword'] = result[nts[0]][int(nts[1])]  # e.g., driving time, network distance
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'networkQ':
            coreType = {}
            nts = coreDict['text'][coreDict['tag'].index('networkQ')].split(' ')
            coreType['type'] = nts[0]
            coreType['id'] = str(core_id)
            coreType['keyword'] = result[nts[0]][int(nts[1])]  # e.g., driving time, network distance
            coreType['measureLevel'] = nts[2]
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'coreC':
            if csign == 1:
                continue
            else:
                clocs = [x for x, y in enumerate(coreDict['tag']) if y == cur_tag]
                # if len(clocs) == 2 and any('conamount' in e for e in coreDict['text']):
                #     conAi = [x for x,y in enumerate(coreDict['text']) if y.startswith('conamount')]
                #     conAts = coreDict['text'][conAi[0]].split(' ')
                #     conA_Rei = [x for x in clocs if not x in conAi]
                #     conA_Reits = coreDict['text'][conA_Rei[0]].split(' ')
                #     coreType = {}
                #     if 'event' in conA_Reits:
                #         coreType['type'] = 'eveconamount'  # number of event -> eveconamount
                #         coreDict['text'] = ['eveconamount']
                #     elif 'object' in conA_Reits:
                #         coreType['type'] = ['objconamount']  # number of object -> objconamount
                #         coreDict['text'] = ['objconamount']
                #     coreType['id'] = str(core_index)
                #     coreType['keyword'] = 'number of ' + result[conA_Reits[0]][int(conA_Reits[1])]
                #     coreType['measureLevel'] = conAts[2]
                #     corety.append(coreType)
                #     coreDict['tag'] = ['coreC']
                #     coreDict.setdefault('id', []).append(str(core_index))
                #     core_index += 1
                # else:
                for cloc in clocs:
                    coreType = {}
                    cts = coreDict['text'][cloc].split(' ')
                    if len(cts) == 2:  # object 0
                        coreType['type'] = cts[0]
                        coreType['id'] = str(core_id)
                        coreType['keyword'] = result[cts[0]][int(cts[1])]
                        corety.append(coreType)
                        coreDict.setdefault('id', []).append(str(core_id))
                        core_id += 1
                    elif len(cts) == 3:  # # eveconobjconpro 0 ira
                        coreType['type'] = cts[0]
                        coreType['id'] = str(core_id)
                        coreType['keyword'] = result[cts[0]][int(cts[1])]
                        coreType['measureLevel'] = cts[2]
                        corety.append(coreType)
                        coreDict.setdefault('id', []).append(str(core_id))
                        core_id += 1
                csign += 1
        elif cur_tag == 'destination':
            des_id = []
            for d in coreDict['text'][coreDict['tag'].index(cur_tag)]:
                coreType = {}
                dtext = d.split(' ')
                if dtext[0] == 'placename':
                    coreType['type'] = 'object'
                else:
                    coreType['type'] = dtext[0]
                coreType['id'] = str(core_id)
                coreType['keyword'] = result[dtext[0]][int(dtext[1])]
                corety.append(coreType)
                des_id.append(str(core_id))
                core_id += 1
            coreDict.setdefault('id', []).append(des_id)
        elif cur_tag == 'origin':
            ori_id = []
            for o in coreDict['text'][coreDict['tag'].index(cur_tag)]:
                coreType = {}
                if 'grid' in o:
                    coreType['type'] = 'grid'
                    coreType['id'] = str(core_id)
                    coreType['keyword'] = o
                    corety.append(coreType)
                    ori_id.append(str(core_id))
                    core_id += 1
                else:
                    otext = o.split(' ')
                    if otext[0] == 'placename':
                        coreType['type'] = 'object'
                    else:
                        coreType['type'] = otext[0]
                    coreType['id'] = str(core_id)
                    coreType['keyword'] = result[otext[0]][int(otext[1])]
                    corety.append(coreType)
                    ori_id.append(str(core_id))
                    core_id += 1
            coreDict.setdefault('id', []).append(ori_id)
        elif cur_tag == 'extent':
            coreType = {}
            coreType['type'] = 'object'
            coreType['id'] = str(core_id)
            coreType['keyword'] = result['placename'][int(coreDict['text'][0].split(' ')[1])]
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1

    # if 'networkC' in coreDict['tag'] and 'coreC' not in coreDict['tag'] and not [i for i, d in enumerate(corety) if
    #                                                                              'placename' in d['type']]:
    #     coreType = {}
    #     # add road as object or network for serviceObj, network analysis
    #     coreType['type'] = ['network', 'object']
    #     coreType['id'] = str(core_id)
    #     coreType['keyword'] = 'road data'  # e.g., driving time, network distance
    #     corety.append(coreType)
    #     coreDict['tag'].insert(coreDict['tag'].index('networkC'), 'roadData')
    #     coreDict['text'].insert(coreDict['tag'].index('roadData'), '')
    #     coreDict['id'].insert(coreDict['tag'].index('roadData'), str(core_id))
    #     core_id += 1
    # if ('serviceObj' in coreDict['tag'] and not 'networkC' in coreDict['tag']) and 'coreC' not in coreDict[
    #     'tag'] and not [i for i, d in enumerate(corety) if 'placename' in d['type']]:
    #     coreType = {}
    #     # add road as object or network for serviceObj, network analysis
    #     coreType['type'] = ['network', 'object']
    #     coreType['id'] = str(core_id)
    #     coreType['keyword'] = 'road data'  # e.g., driving time, network distance
    #     corety.append(coreType)
    #     coreDict['tag'].insert(coreDict['tag'].index('serviceObj'), 'roadData')
    #     coreDict['text'].insert(coreDict['tag'].index('roadData'), '')
    #     coreDict['id'].insert(coreDict['tag'].index('roadData'), str(core_id))
    #     core_id += 1

    return corety, coreDict


# [X] Generate parser tree of question by the GeoAnQu grammar and extract core concept transformations
def geo_parser(sentence):
    global result
    global core_id
    global coreConTrans

    ques_incorrect = ''

    coreTypes = {}
    wei_len = 0

    input = InputStream(sentence)  # [X]sentence =  'What areas are with slope larger than 10 in Spain'
    lexer = GeoAnQuLexer(input)  # get lexer rule
    stream = CommonTokenStream(lexer)  # token stream to tokens
    parser = GeoAnQuParser(stream)
    try:
        tree = parser.start()  # [X] get parsed tree of the sentence
        treeStr = Trees.toStringTree(tree, None, parser)  # Print out a whole tree in LISP form
        quesTextDic = get_text(treeStr)

        # print(treeStr)

        sequence = [ele for ele in quesTextDic['tag'] if ele in que_stru]
        sequence.reverse()
        # print(sequence)

        if 'condition' in sequence:
            conCores = []
            con_count = treeStr.count('condition')
            for cur_i in range(0, con_count):
                con_treeStr = Trees.toStringTree(tree.condition(cur_i), None, parser)
                conTextDic = get_text(con_treeStr)
                if 'date' in conTextDic['tag'] and 'coreC' not in conTextDic['tag']:
                    conCore = {}
                    conCore['tag'] = ['compareR']
                    conCore['text'] = [conTextDic['text'][conTextDic['tag'].index('date')]]
                else:
                    conCore = core_concept_extract(conTextDic)
                if 'destination' in conTextDic['tag']:
                    des_list = []
                    if 'serviceObj' in conTextDic['tag']:
                        destination = tree.condition(cur_i).boolField().serviceObj().destination()
                        dest_childCount = destination.getChildCount()
                    elif 'distField' in conTextDic['tag']:
                        destination = tree.condition(cur_i).boolField().distField().destination(0)
                        dest_childCount = destination.getChildCount()
                    else:
                        destination = tree.condition(cur_i).destination()
                        dest_childCount = destination.getChildCount()
                    for d_i in range(0, dest_childCount):
                        dest_text = destination.getChild(d_i).getText()
                        if 'object' in dest_text or 'event' in dest_text:
                            dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                            des_list.append(dest_text)
                        elif 'placename' in dest_text:
                            dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                            des_list.append(dest_text)
                    des_list.reverse()
                    conCore['tag'].append('destination')
                    conCore['text'].append(des_list)
                if 'origin' in conTextDic['tag']:  # 'centriods of object/grid' or 'object' or 'grid'
                    if 'serviceObj' in conTextDic['tag']:
                        origin = tree.condition(cur_i).boolField().serviceObj().origin()
                        ori_childCount = origin.getChildCount()
                    elif 'distField' in conTextDic['tag']:
                        origin = tree.condition(cur_i).boolField().distField().origin(0)
                        ori_childCount = origin.getChildCount()
                    else:
                        origin = tree.condition(cur_i).origin()
                        ori_childCount = origin.getChildCount()
                    for o_i in range(0, ori_childCount):
                        ori_list = []
                        ori_text = origin.getChild(o_i).getText()
                        if 'object' in ori_text or 'event' in ori_text:
                            ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                            ori_list.append(ori_text)
                        elif 'grid' in ori_text:
                            if 'equantity' in ori_text:
                                ein = ori_text.index('equantity') + 9
                                ori_text = ori_text.replace('equantity' + ori_text[ein],
                                                            result['quantity'][int(ori_text[ein])] + ' ')
                            if 'of' in ori_text:
                                ori_text = ori_text.replace('of', 'of ')
                            if 'with' in ori_text:
                                ori_text = ori_text.replace('with', ' with ')
                            ori_list.append(ori_text.strip())
                            # ori_list in forward order, e.g, [object0, grid], object = centroid
                        elif 'placename' in ori_text:
                            ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                            ori_list.append(ori_text.strip())
                    #-------new---------
                    ori_list.reverse()
                    conCore['tag'].append('origin')
                    conCore['text'].append(ori_list)
                    # -------new---------
                if 'grid' in conTextDic['tag'] and 'origin' not in conTextDic['tag'] and 'destination' not in \
                        conTextDic['tag']:
                    cgrid_text = tree.condition(cur_i).grid().getText()
                    if 'equantity' in cgrid_text:
                        ein = cgrid_text.index('equantity') + 9
                        cgrid_text = cgrid_text.replace('equantity' + cgrid_text[ein],
                                                        result['quantity'][int(cgrid_text[ein])] + ' ')
                    conCore['tag'].append('grid')
                    conCore['text'].append(cgrid_text)
                # if 'densityNei' in conTextDic['tag']:
                #     denN_in = conTextDic['tag'].index('densityNei')
                #     denN_text = conTextDic['text'][denN_in+1] + ' ' + conTextDic['text'][denN_in]
                #     conCore['tag'].append('density Neighbor')
                #     conCore['text'].append(denN_text)
                conCore['tag'].reverse()
                conCore['text'].reverse()
                conCores.insert(0, conCore)

        if 'measure' in sequence:
            mea_treeStr = Trees.toStringTree(tree.measure(), None, parser)
            meaTextDic = get_text(mea_treeStr)
            meaCore = core_concept_extract(meaTextDic)
            if 'destination' in meaTextDic['tag']:
                destination = tree.measure().destination(0)
                dest_childCount = destination.getChildCount()  # 'closest object0', childcount = 2
                des_list = []
                for d_i in range(0, dest_childCount):
                    dest_text = destination.getChild(d_i).getText()
                    if 'object' in dest_text or 'event' in dest_text:
                        dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                        des_list.append(dest_text)
                    elif 'placename' in dest_text:
                        dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                        des_list.append(dest_text.strip())
                des_list.reverse()
                meaCore['tag'].append('destination')
                meaCore['text'].append(des_list)
            if 'origin' in meaTextDic['tag']:  # 'centriods of object/grid' or 'object' or 'grid'
                origin = tree.measure().origin(0)
                ori_childCount = origin.getChildCount()
                ori_list = []
                for o_i in range(0, ori_childCount):
                    ori_text = origin.getChild(o_i).getText()
                    if 'object' in ori_text or 'event' in ori_text:
                        ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                        ori_list.append(ori_text)
                    elif 'grid' in ori_text:
                        if 'equantity' in ori_text:
                            ein = ori_text.index('equantity') + 9
                            ori_text = ori_text.replace('equantity' + ori_text[ein],
                                                        result['quantity'][int(ori_text[ein])] + ' ')
                        if 'of' in ori_text:
                            ori_text = ori_text.replace('of', 'of ')
                        if 'with' in ori_text:
                            ori_text = ori_text.replace('with', ' with ')
                        ori_list.append(ori_text.strip())
                        # ori_list in forward order, e.g, [object0, grid], object = centroid
                    elif 'placename' in ori_text:
                        ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                        ori_list.append(ori_text.strip())
                ori_list.reverse()
                if 'destination' in meaTextDic['tag'] and quesTextDic['tag'].index('destination') > quesTextDic['tag'].index('origin'):
                    meaCore['text'].insert(meaCore['tag'].index('destination'), ori_list)
                    meaCore['tag'].insert(meaCore['tag'].index('destination'),'origin')
                else:
                    meaCore['tag'].append('origin')
                    meaCore['text'].append(ori_list)
            meaCore['tag'].reverse()
            meaCore['text'].reverse()
            if 'weight' in meaTextDic['tag']:
                wei_loc = meaTextDic['tag'].index('weight')
                wei_len = len(meaTextDic['tag']) - wei_loc - 1

        if 'measure1' in sequence:
            mea1_treeStr = Trees.toStringTree(tree.measure1(), None, parser)
            mea1TreeDic = get_text(mea1_treeStr)
            mea1Core = core_concept_extract(mea1TreeDic)

        if 'subcon' in sequence:
            subcon_treeStr = Trees.toStringTree(tree.subcon(), None, parser)
            subconTextDic = get_text(subcon_treeStr)
            subconCore = core_concept_extract(subconTextDic)
            subconCore['tag'].reverse()
            subconCore['text'].reverse()

        if 'support' in sequence:
            sup_treeStr = Trees.toStringTree(tree.support(), None, parser)
            supTextDic = get_text(sup_treeStr)
            supCore = core_concept_extract(supTextDic)
            if 'grid' in supTextDic['tag']:
                grid_text = tree.support().grid().getText()
                if 'equantity' in grid_text:
                    ein = grid_text.index('equantity') + 9
                    grid_text = grid_text.replace('equantity' + grid_text[ein],
                                                  result['quantity'][int(grid_text[ein])] + ' ')
                supCore['tag'].append('grid')
                supCore['text'].append(grid_text)
            if 'distBand' in supTextDic['tag']:
                distBand_text = tree.support().distBand().getText()
                if 'equantity' in distBand_text:
                    eins = [m.start() for m in re.finditer('equantity', distBand_text)]
                    e = 9
                    for ein in eins:
                        distBand_text = distBand_text.replace('equantity' + distBand_text[ein + e],
                                                              ' equantity ' + distBand_text[ein + e] + ' ')
                        e = e + 3
                    dBts = distBand_text.split(' ')
                    eqins = [x for x, y in enumerate(dBts) if y == 'equantity']
                    qlocs = []
                    for eqin in eqins:
                        qlocs.append(dBts[eqin + 1])
                    for qloc in qlocs:
                        distBand_text = distBand_text.replace(
                            'equantity ' + distBand_text[distBand_text.index('equantity') + 10],
                            result['quantity'][int(qloc)])
                supCore['tag'].append('distanceBand')
                supCore['text'].append(distBand_text.strip())
            supCore['tag'].reverse()
            supCore['text'].reverse()

        for seq in sequence:
            if seq == 'measure':
                meaTypes = write_type(meaCore)
                coreConTrans.setdefault('types', []).extend(meaTypes[0])  # type info in the final results
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(meaTypes[1])
                if wei_len:
                    coreTypes['weight'] = wei_len
            elif seq == 'measure1':
                mea1Types = write_type(mea1Core)
                coreConTrans.setdefault('types', []).extend(mea1Types[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(mea1Types[1])
            elif seq == 'condition':
                conTypes = write_type(conCores[0])
                coreConTrans.setdefault('types', []).extend(conTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(conTypes[1])
                conCores.pop(0)
            elif seq == 'subcon':
                subconTypes = write_type(subconCore)
                coreConTrans.setdefault('types', []).extend(subconTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(subconTypes[1])
            elif seq == 'support':
                supTypes = write_type(supCore)
                coreConTrans.setdefault('types', []).extend(supTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(supTypes[1])

        ext_count = treeStr.count('extent')
        if ext_count:
            for cur_i in range(0, ext_count):
                ext_treeStr = Trees.toStringTree(tree.extent()[cur_i], None, parser)
                extTextDic = get_text(ext_treeStr)
                extTypes = write_type(extTextDic)
                coreConTrans.setdefault('types', []).extend(extTypes[0])
                coreConTrans.setdefault('extent', []).append(extTypes[1]['id'][0])
            coreTypes.setdefault('funcRole', []).append('extent')
            coreTypes.setdefault('types', []).append(extTypes[1]['id'])

        tem_count = treeStr.count('temEx')
        if tem_count:
            for cur_t in range(0, tem_count):
                tem_treeStr = Trees.toStringTree(tree.temEx(cur_t), None, parser)
                temTextDic = get_text(tem_treeStr)
                temsp = temTextDic['text'][0].split(' ')
                coreConTrans.setdefault('temporalEx', []).append(result['date'][int(temsp[1])])
            coreTypes.setdefault('funcRole', []).append('temEx')
            coreTypes.setdefault('types', []).append(coreConTrans['temporalEx'])

        print('coreTypes:', coreTypes)
        print('coreConTrans:', coreConTrans)

    except:
        ques_incorrect = sentence

    return treeStr, coreTypes, ques_incorrect


# generate type for a subset of a concept. only change id. keywords and type remain same.
def new_type(curid):
    global core_id
    global coreConTrans

    newtype_index = [i for i, j in enumerate(coreConTrans['types']) if j['id'] == curid][
        0]  # find index for the subset transcross_condi['after']
    newtype = coreConTrans['types'][newtype_index].copy()  # copy type for the subset
    newtype['id'] = str(core_id)  # update id for the subset

    return newtype


# [X] Generate core concept transformations within condition, measure...
# Input TypeDict = {'tag': ['coreC', 'distField', 'boolField'], 'text': ['object 1', 'from', ''], 'id': ['1', '2', '3']}
# Output [{'before': ['1'], 'after': ['2']}, {'before': ['2'], 'after': ['3']}]
def write_trans_within(TypeDict):
    global core_id
    global coreConTrans
    global measureType
    transwithin = []
    coreC_sign = 0

    for tt in TypeDict['tag']:
        if (tt == 'boolfield' and 'serviceobj' not in TypeDict['tag']) or tt == 'allocation' or tt == 'conAm':
            if TypeDict['tag'].index(tt) - 1 >= 0:
                trans = {}
                trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
                trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
                transwithin.append(trans)
        elif tt == 'distfield':
            if TypeDict['tag'].index(tt) - 1 >= 0:
                cur_tag = TypeDict['tag'][TypeDict['tag'].index(tt) - 1]
                if cur_tag == 'networkC':  # networkC -> object -> distField
                    trans_net = {}
                    trans_net['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
                    trans_net['after'] = [str(core_id)]
                    transwithin.append(trans_net)
                    # add object in types
                    dist_index = [i for i, j in enumerate(coreConTrans['types']) if j['type'] == 'distfield'][0]
                    coreConTrans.setdefault('types', []).append({'type': 'object', 'id': str(core_id),
                                                                 'keyword': coreConTrans['types'][dist_index - 1][
                                                                     'keyword']})
                    # object -> distField
                    trans = {}
                    trans['before'] = [str(core_id)]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
                    transwithin.append(trans)
                    core_id += 1
                elif cur_tag == 'coreC':
                    trans = {}
                    trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
                    transwithin.append(trans)
        elif tt == 'location' and 'allocation' not in TypeDict['tag']:
            trans = {}
            trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
            trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
            transwithin.append(trans)
        elif tt == 'serviceobj':
            s_in = TypeDict['tag'].index(tt)
            trans = {}
            #-------new----------
            if s_in - 2 >= 0 and TypeDict['tag'][s_in - 2] == 'destination':
                if s_in - 3 >= 0 and TypeDict['tag'][
                    s_in - 3] == 'origin':  # ['origin', 'destination', 'networkC', 'serviceObj'], remove 'roadData'
                    if len(TypeDict['id'][
                               s_in - 3]) == 2:  # [['grid', 'centroid'], 'destination', 'networkC', 'serviceObj'], remove 'roadData'
                        trans['before'] = [TypeDict['id'][s_in - 3][0]]
                        trans['after'] = [TypeDict['id'][s_in - 3][1]]
                        transwithin.append(trans)
                    # origin: TypeDict['id'][s_in - 3], destination: TypeDict['id'][s_in - 2], remove roadData
                    # networkC is not used here.
                    trans = {}
                    trans['before'] = [TypeDict['id'][s_in - 3][-1], TypeDict['id'][s_in - 2][-1]]
                    trans['after'] = [TypeDict['id'][s_in-1]]
                    transwithin.append(trans)
                    trans_service = {}  # driving time -> 1 min driving time
                    trans_service['before'] = [TypeDict['id'][s_in - 1]]
                    trans_service['after'] = [str(core_id)]
                    transwithin.append(trans_service)
                    coreConTrans.setdefault('types', []).append(new_type(trans_service['before'][0]))
                    core_id += 1
                # elif s_in - 3 < 0 or TypeDict['tag'][
                #     0] == 'destination':  # ['destination', 'networkC', 'serviceObj'], remove 'roadData'
                #     trans['before'] = [TypeDict['id'][s_in - 2][-1]]
                #     trans['after'] = [TypeDict['id'][s_in]]
                #     transwithin.append(trans)
            elif s_in - 2 >= 0 and TypeDict['tag'][
                s_in - 2] == 'origin':  # ['origin', 'networkC', 'serviceObj'], remove 'roadData'
                if len(TypeDict['id'][
                           s_in - 2]) == 2:  # [['grid', 'centroid'], 'networkC', 'serviceObj'], remove 'roadData'
                    trans['before'] = [TypeDict['id'][s_in - 2][0]]
                    trans['after'] = [TypeDict['id'][s_in - 2][1]]
                    transwithin.append(trans)
                trans = {} # origin, measure_obj -> driving time
                trans['before'] = [TypeDict['id'][s_in - 2][-1], measureType['id'][0]]
                trans['after'] = [TypeDict['id'][s_in-1]]
                transwithin.append(trans)
                trans_ser = {} # driving time -> 1 min driving time
                trans_ser['before'] = [TypeDict['id'][s_in - 1]]
                trans_ser['after'] = [str(core_id)]
                transwithin.append(trans_ser)
                coreConTrans.setdefault('types', []).append(new_type(trans_ser['before'][0]))
                core_id += 1
            # duplicate?
            #  s_in - 1 >= 0 and TypeDict['tag'][
            #     s_in - 2] == 'origin':  # ['origin', 'serviceObj'], remove 'roadData'
            #     if len(TypeDict['id'][s_in - 2]) == 2:  # [['grid', 'centroid'], 'serviceObj'], remove 'roadData'
            #         trans['before'] = [TypeDict['id'][s_in - 2][0]]
            #         trans['after'] = [TypeDict['id'][s_in - 2][1]]
            #         transwithin.append(trans)
            #     trans = {}
            #     trans['before'] = [TypeDict['id'][s_in - 2][-1]]
            #     trans['after'] = [TypeDict['id'][s_in]]
            #     transwithin.append(trans)
            # -------new----------
        elif (tt == 'networkC' or tt == 'networkQ') and (
                'destination' in TypeDict['tag'] or 'origin' in TypeDict['tag']) and 'serviceobj' not in TypeDict[
            'tag']:
            n_in = TypeDict['tag'].index(tt)
            trans = {}
            if 'destination' in TypeDict['tag']:
                desti_loc = TypeDict['tag'].index('destination')
                if 'origin' in TypeDict['tag']:  # ['origin', 'destination', 'networkC'] //'roadData',
                    orig_loc = TypeDict['tag'].index('origin')
                    if len(TypeDict['id'][orig_loc]) == 2:  # [['grid', 'centroid'], 'destination', 'networkC'] //'roadData'
                        trans['before'] = [TypeDict['id'][orig_loc][0]]
                        trans['after'] = [TypeDict['id'][orig_loc][1]]
                        transwithin.append(trans)
                    # origin: TypeDict['id'][n_in - 2], destination: TypeDict['id'][n_in - 1], // remove roadData:TypeDict['id'][n_in - 1]
                    trans = {}
                    trans['before'] = [TypeDict['id'][orig_loc][-1], TypeDict['id'][desti_loc][-1]]
                    trans['after'] = [TypeDict['id'][n_in]]
                    transwithin.append(trans)
                else:  # ['destination', 'networkC'] //'roadData'
                    trans['before'] = [TypeDict['id'][desti_loc][-1]]
                    trans['after'] = [TypeDict['id'][n_in]]
                    transwithin.append(trans)
            elif n_in - 1 >= 0 and TypeDict['tag'][n_in - 1] == 'origin':  # ['origin', 'networkC'] //'roadData',
                if len(TypeDict['id'][n_in - 1]) == 2:  # [['grid', 'centroid'], 'networkC'] //'roadData',
                    trans['before'] = [TypeDict['id'][n_in - 1][0]]
                    trans['after'] = [TypeDict['id'][n_in - 1][1]]
                    transwithin.append(trans)
                trans = {}
                trans['before'] = [TypeDict['id'][n_in - 1][-1]]
                trans['after'] = [TypeDict['id'][n_in]]
                transwithin.append(trans)
            # TODO: duplicate? [origin([object1]), netoworkC]
            # elif n_in - 1 >= 0 and TypeDict['tag'][n_in - 1] == 'origin':
            #     trans = {}
            #     trans['before'] = [TypeDict['id'][n_in - 1][0]]
            #     trans['after'] = [TypeDict['id'][n_in]]
            #     transwithin.append(trans)
        elif tt == 'extreDist' and TypeDict['tag'][TypeDict['tag'].index('extreDist') - 1] == 'networkQ':
            trans = {}
            trans['before'] = [TypeDict['id'][TypeDict['tag'].index('extreDist') - 1]]
            trans['after'] = [str(core_id)]
            transwithin.append(trans)
            # add object quality in types
            net_index = [i for i, j in enumerate(coreConTrans['types']) if j['id'] == trans['before'][0]][0]
            coreConTrans.setdefault('types', []).append(
                {'type': 'objectquality', 'id': str(core_id),
                 'keyword': TypeDict['text'][TypeDict['tag'].index('extreDist')] + ' ' +
                            coreConTrans['types'][net_index]['keyword'], 'measureLevel': 'ratio'})
            core_id += 1
        elif tt == 'compareR' and len(TypeDict['tag']) == 2:
            trans = {}
            trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
            trans['after'] = [str(core_id)]
            transwithin.append(trans)
            coreConTrans.setdefault('types', []).append(new_type(trans['before'][0]))
            core_id += 1
        elif tt == 'coreC' and 'serviceobj' not in TypeDict['tag'] and 'networkC' not in TypeDict['tag']:
            trans = {}
            if 'destination' in TypeDict['tag']:
                if 'origin' in TypeDict['tag']:  # access score
                    oin = TypeDict['tag'].index('origin')
                    if len(TypeDict['id'][oin]) == 2:
                        trans['before'] = [TypeDict['id'][oin][0]]
                        trans['after'] = [TypeDict['id'][oin][1]]
                        transwithin.append(trans)
                    trans = {}
                    trans['before'] = [TypeDict['id'][oin][-1],
                                       TypeDict['id'][TypeDict['tag'].index('destination')][-1]]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index('coreC')]]
                    transwithin.append(trans)
                elif 'origin' not in TypeDict['tag']:  # Euclidean distance to object
                    trans = {}
                    trans['before'] = [TypeDict['id'][TypeDict['tag'].index('destination')][-1]]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index('coreC')]]
                    transwithin.append(trans)
            else:
                if coreC_sign == 1:
                    continue
                else:
                    coreC_loc = [x for x, y in enumerate(TypeDict['tag']) if y == 'coreC']
                    for coreC_l in coreC_loc:
                        if coreC_l < coreC_loc[-1]:
                            trans = {}
                            trans['before'] = [TypeDict['id'][coreC_l]]
                            trans['after'] = [TypeDict['id'][coreC_l + 1]]
                            transwithin.append(trans)
                coreC_sign = 1

    if 'networkC' in TypeDict['tag'] and TypeDict['tag'].index('networkC') + 1 < len(TypeDict['tag']) and \
            TypeDict['tag'][TypeDict['tag'].index('networkC') + 1] == 'coreC':
        net_index = TypeDict['tag'].index('networkC')
        trans = {}
        trans['before'] = [TypeDict['id'][net_index]]
        trans['after'] = [TypeDict['id'][net_index + 1]]
        transwithin.append(trans)

    return transwithin


# Input coreTypeDict = coreTypes:
#   {'funcRole': ['condition', 'condition', 'measure', 'extent', 'temEx'],
# 	 'types': [{'tag': ['coreC', 'distField', 'boolField'], 'text': ['object 1', 'from', ''], 'id': ['0', '1', '2']},
# 			   {'tag': ['coreC'], 'text': ['objectquality 0 boolean'], 'id': ['3']},
# 			   {'tag': ['coreC'], 'text': ['object 0'], 'id': ['4']},
# 			   ['Utrecht'],
# 			   ['2030']]}
# coreTransType = coreConTrans
#   {'types': [{'type':'object', 'id':'0', keyword:'district'},
#              {'type':'distField', 'id':'1', keyword:''},
#              {'type':'boolField', 'id':'2', keyword:''},
#               ...]}
def write_trans(coreTypeDict):
    try:
        global core_id
        global coreConTrans
        global measureType
        global result
        coretrans = []
        subis = []
        conis = []
        supis = []
        meais = []
        mea1is = []
        con_supis = []
        mc = []  # if condition number = 2, need to combine m*condition1 and m*condition2

        if 'subcon' in coreTypeDict['funcRole']:
            subis = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'subcon']
        if 'condition' in coreTypeDict['funcRole']:
            conis = [x for x, y in enumerate(coreTypeDict['funcRole']) if
                     (y == 'condition' and coreTypeDict['types'][x]['tag'])]
        if 'support' in coreTypeDict['funcRole']:
            supis = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'support']
        if 'measure' in coreTypeDict['funcRole']:
            meais = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'measure']
            measureType = coreTypeDict['types'][meais[0]]
        if 'measure1' in coreTypeDict['funcRole']:
            mea1is = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'measure1']

        if supis:
            conar = numpy.array(conis)
            supar = numpy.array(supis)
            con_supis = list(conar[conar < supar])
            con_meais = [x for x in conis if x not in con_supis]
        else:
            con_meais = conis

        if subis:
            if len(coreTypeDict['types'][subis[0]]['tag']) > 1:
                #---------new--------
                if ('compareR' in coreTypeDict['types'][subis[0]]['tag'] and
                    coreTypeDict['types'][subis[0]]['tag'].index('compareR') + 1 < 2 and
                    'pro' not in coreTypeDict['types'][subis[0]]['text'][
                        coreTypeDict['types'][subis[0]]['tag'].index('compareR') + 1]) or "boolfield" in \
                        coreTypeDict['types'][subis[0]]['tag']:
                    sub_trans = write_trans_within(coreTypeDict['types'][subis[0]])
                    coretrans.extend(sub_trans)
                #---------new--------
            if coreTypeDict['funcRole'][subis[0] + 1] == 'condition':
                transcross = {}
                # if coreTypeDict['types'][subis[0] + 1]['tag'][0] == 'origin':  # TODO: update later, do not have such questions?
                #     transcross['before'] = [coreTypeDict['types'][subis[0] + 1]['id'][0][0],
                #                             coreTypeDict['types'][subis[0]]['id'][-1]]
                #     transcross['after'] = [coreTypeDict['types'][subis[0] + 1]['id'][0][0] + sign]
                #     coreTypeDict['types'][subis[0] + 1]['id'][0][0] = transcross['after'][0]
                # else:
                transcross['before'] = [coreTypeDict['types'][subis[0] + 1]['id'][0],
                                        coreTypeDict['types'][subis[0]]['id'][-1]]
                transcross['after'] = [str(core_id)]
                coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][subis[0] + 1]['id'][0]))
                if 'amount' in coreTypeDict['types'][subis[0] + 1]['text'][0] and 'distfield' in coreTypeDict['types'][subis[0]]['tag']:
                    distf_index = coreTypeDict['types'][subis[0]]['tag'].index('distfield')
                    transcross['key'] = coreTypeDict['types'][subis[0]]['id'][distf_index]
                coreTypeDict['types'][subis[0] + 1]['id'][0] = transcross['after'][0]
                core_id += 1
                coretrans.append(transcross)

        if con_supis:
            if len(coreTypeDict['types'][con_supis[0]]['tag']) > 1:
                con_sup_trans = write_trans_within(coreTypeDict['types'][con_supis[0]])
                coretrans.extend(con_sup_trans[0])
            transcross = {}
            transcross['before'] = [coreTypeDict['types'][supis[0]]['id'][0],
                                    coreTypeDict['types'][con_supis[0]]['id'][-1]]
            transcross['after'] = [str(core_id)]
            coretrans.append(transcross)
            coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][supis[0]]['id'][0]))
            coreTypeDict['types'][supis[0]]['id'][0] = transcross['after'][0]
            core_id += 1

        # if there is transformations within support, no such question in GeoAnQu
        if supis and len(coreTypeDict['types'][supis[0]]['tag']) > 1:
            sup_trans = write_trans_within(coreTypeDict['types'][supis[0]])
            coretrans.extend(sup_trans)

        if con_meais:
            for ci in con_meais:
                if any('proportion' in e for e in coreTypeDict['types'][ci]['text']):
                    amount_id = coreTypeDict['types'][ci]['id'][0:-1]
                    if amount_id:
                        transcross = {}
                        transcross['before'] = amount_id
                        transcross['after'] = [coreTypeDict['types'][ci]['id'][-1]]
                        # Which park has the highest proportion of bald eagles to the bird totals in Texas, extremaR is not considered here.
                        if coreTypeDict['types'][meais[0]]['tag'] == ['coreC']:
                            transcross['key'] = coreTypeDict['types'][meais[0]]['id'][0]
                        coretrans.append(transcross)
                    elif not amount_id and len(coreTypeDict['types'][ci]['tag']) > 1:
                        con_mea_trans = write_trans_within(coreTypeDict['types'][ci])
                        coretrans.extend(con_mea_trans)
                        if 'compareR' in coreTypeDict['types'][ci]['tag']:
                            compR_index = coreTypeDict['types'][ci]['tag'].index('compareR')
                            coreTypeDict['types'][ci]['id'][compR_index] = con_mea_trans[0]['after'][0]
                elif len(coreTypeDict['types'][ci]['tag']) > 1 and not any(
                        'aggre' in e for e in coreTypeDict['types'][ci]['tag']) and not any(
                    'proportion' in e for e in coreTypeDict['types'][ci]['text']):
                    con_mea_trans = write_trans_within(coreTypeDict['types'][ci])
                    coretrans.extend(con_mea_trans)
                    if 'serviceobj' in coreTypeDict['types'][ci]['tag']:
                        coreTypeDict['types'][ci]['id'][-1] = con_mea_trans[-1]['after'][0]
                    if 'compareR' in coreTypeDict['types'][ci]['tag']:
                        compR_index = coreTypeDict['types'][ci]['tag'].index('compareR')
                        coreTypeDict['types'][ci]['id'][compR_index] = con_mea_trans[0]['after'][0]
                # TODO: update later, if aggre in condition, seems no such question in GeoAnQu
                elif any('aggre' in e for e in coreTypeDict['types'][ci]['tag']):
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][ci]['id'][-2]]
                    transcross['after'] = [coreTypeDict['types'][ci]['id'][-1]]
                    coretrans.append(transcross)



        if meais:
            if any('proportion' in e for e in coreTypeDict['types'][meais[0]]['text']) or any('eveconobjconpro' in e for e in coreTypeDict['types'][meais[0]]['text']):  #-------new---------
                # for m in coreTypeDict['types'][meais[0]]['text']:  # if measure = proportion, turn object into objconAmount
                #     if m.startswith('object'):  # object -> object content amount
                #         mi = coreTypeDict['types'][meais[0]]['text'].index(m)
                #         mid = coreTypeDict['types'][meais[0]]['id'][mi]
                #         for ele in coreTransType['types']:
                #             if ele['id'] == mid:
                #                 ele['type'] = 'objconamount'
                #                 ele['keyword'] = 'number of ' + ele['keyword']
                #                 ele['measureLevel'] = 'count'
                #     elif m.startswith('event'):  # event -> event content amount
                #         mi = coreTypeDict['types'][meais[0]]['text'].index(m)
                #         mid = coreTypeDict['types'][meais[0]]['id'][mi]
                #         for ele in coreTransType['types']:
                #             if ele['id'] == mid:
                #                 ele['type'] = 'eveconamount'
                #                 ele['keyword'] = 'number of ' + ele['keyword']
                #                 ele['measureLevel'] = 'count'
                amount_id = coreTypeDict['types'][meais[0]]['id'][0:-1]
                if amount_id:
                    if supis and not con_meais:
                        for a in amount_id:
                            a_index = coreTypeDict['types'][meais[0]]['id'].index(a)
                            if 'amount' in coreTypeDict['types'][meais[0]]['text'][a_index]:
                                transcross = {}  # objconA * support -> content Amount
                                transcross['before'] = [a, coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross['after'] = [str(core_id)]
                                transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(new_type(a))
                                coreTypeDict['types'][meais[0]]['id'][a_index] = transcross['after'][0]
                                core_id += 1
                            elif 'object' in coreTypeDict['types'][meais[0]]['text'][a_index] or 'event' in \
                                    coreTypeDict['types'][meais[0]]['text'][a_index]:
                                transcross = {}  # object * support -> object amount
                                transcross['before'] = [a, coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross['after'] = [str(core_id)]
                                transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'amount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                coreTypeDict['types'][meais[0]]['id'][coreTypeDict['types'][meais[0]]['id'].index(a)] = \
                                transcross['after'][0]  # why change id?
                                core_id += 1
                            elif 'field' in coreTypeDict['types'][meais[0]]['text'][
                                a_index]:  # percentage of water areas for each PC4
                                transcross = {}  # field * support -> field coverage amount
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                        coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross['after'] = [str(core_id)]
                                transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                core_id += 1
                        if not mea1is:
                            if len(coreTypeDict['types'][meais[0]]['id']) > 2:  # [amount+amount, proportion]
                                transcross = {}  # objconA * objconA  = proportion
                                transcross['before'] = coreTypeDict['types'][meais[0]]['id'][0:-1]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coretrans.append(transcross)
                            elif len(coreTypeDict['types'][meais[0]]['id']) == 2:  # [field/object/event, proportion]
                                transcross = {}  # support -> support coverage amount
                                transcross['before'] = [coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross['after'] = [str(core_id)]
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                # field coverage amount * support coverage amount = proportion
                                transcross = {}
                                transcross['before'] = [str(core_id - 1), str(core_id)]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coretrans.append(transcross)
                                core_id += 1
                        elif mea1is:
                            a1 = coreTypeDict['types'][mea1is[0]]['id'][-1]
                            transcross = {}
                            transcross['before'] = [a1, coreTypeDict['types'][supis[0]]['id'][-1]]
                            transcross['after'] = [str(core_id)]
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(new_type(a1))
                            coreTypeDict['types'][mea1is[0]]['id'][coreTypeDict['types'][mea1is[0]]['id'].index(a1)] = \
                                transcross['after'][0]
                            core_id += 1
                            transcross = {}  # objconA * objconA  = proportion
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                    coreTypeDict['types'][mea1is[0]]['id'][-1]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                            coretrans.append(transcross)
                    elif con_meais and not supis:
                        if 'id' not in coreTypeDict['types'][con_meais[0]]:  # compareR or extremaR
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                            core_id += 1
                        else:
                            transcross = {}  # objconA * condi = objconA_u  or field * condi = field_u
                            transcross['before'] = [coreTypeDict['types'][con_meais[0]]['id'][-1],
                                                    coreTypeDict['types'][meais[0]]['id'][0]]
                            transcross['after'] = [str(core_id)]
                            if 'amount' in coreTypeDict['types'][meais[0]]['text'][0] and 'distfield' in coreTypeDict['types'][con_meais[0]]['tag']:
                                distf_index = coreTypeDict['types'][con_meais[0]]['tag'].index('distfield')
                                transcross['key'] = coreTypeDict['types'][con_meais[0]]['id'][distf_index]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                            core_id += 1
                        if mea1is:
                            transcross = {}
                            transcross['before'] = [str(core_id - 1),
                                                    coreTypeDict['types'][mea1is[0]]['id'][0]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            transcross['key'] = coreConTrans['extent'][0]
                            coretrans.append(transcross)
                            core_id += 1
                        else:
                            if any('conamount' in e for e in coreTypeDict['types'][meais[0]]['text']):
                                transcross = {}  # objconA_u * objconA = proportion for [condition, objconA, proportion]
                                transcross['before'] = [str(core_id - 1),
                                                        coreTypeDict['types'][meais[0]]['id'][0]]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                transcross['key'] = coreConTrans['extent'][0]
                                coretrans.append(transcross)
                                core_id += 1
                            elif any('field' in e for e in coreTypeDict['types'][meais[0]]['text']):
                                transcross = {}  # field_u -> field coverage amount
                                transcross['before'] = [str(core_id - 1)]  # field_u
                                transcross['after'] = [str(core_id)]  # covamount
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                core_id += 1
                                if 'id' not in coreTypeDict['types'][con_meais[0]]:  # noise larger than 70 db
                                    #  extent -> extent coverage amount
                                    transcross = {}
                                    transcross['before'] = coreConTrans['extent']
                                    transcross['after'] = [str(core_id)]
                                    coretrans.append(transcross)
                                    coreConTrans.setdefault('types', []).append(
                                        {'type': 'covamount', 'id': str(core_id), 'keyword': '',
                                         'measureLevel': 'era'})
                                    # field coverage amount, extent coverage amount -> proportion
                                    transcross = {}
                                    transcross['before'] = [str(core_id - 1), str(
                                        core_id)]  # core_id-1 = field covamount, core_id = extent covamount
                                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                    transcross['key'] = coreConTrans['extent'][0]
                                    coretrans.append(transcross)
                                    core_id += 1
                                else:
                                    # condition -> conidtion coverage amount
                                    transcross = {}
                                    transcross['before'] = [
                                        coreTypeDict['types'][con_meais[0]]['id'][-1]]  # boolfiled or distfield
                                    transcross['after'] = [str(core_id)]
                                    coretrans.append(transcross)
                                    coreConTrans.setdefault('types', []).append(
                                        {'type': 'covamount', 'id': str(core_id), 'keyword': '',
                                         'measureLevel': 'era'})
                                    # field coverage amount * condition coverage amount = proportion
                                    transcross = {}
                                    transcross['before'] = [str(core_id - 1), str(core_id)]
                                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                    transcross['key'] = coreConTrans['extent'][0] #---------new-----
                                    coretrans.append(transcross)
                                    core_id += 1
                            else:
                                transcross = {}  # object_u -> object_u amount
                                transcross['before'] = [str(core_id - 1)]
                                transcross['after'] = [str(core_id)]
                                transcross['key'] = coreConTrans['extent'][
                                    0]  # object to amount need a key, to covamount donot a key?
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'amount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                core_id += 1
                                # object -> object amount
                                transcross = {}  # object -> object amount
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                                transcross['after'] = [str(core_id)]
                                transcross['key'] = coreConTrans['extent'][0]
                                coretrans.append(transcross)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'amount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                # object amount * condition coverage amount = proportion
                                transcross = {}
                                transcross['before'] = [str(core_id - 1), str(core_id)]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                transcross['key'] = coreConTrans['extent'][0]
                                coretrans.append(transcross)
                                core_id += 1
                    elif not supis and not con_meais:
                        # extent -> extent covamount
                        trans_ext = {}
                        trans_ext['before'] = [coreConTrans['extent'][0]]
                        trans_ext['after'] = [str(core_id)]
                        coretrans.append(trans_ext)
                        coreConTrans.setdefault('types', []).append(
                            {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        core_id += 1
                        if any('field' in e for e in coreTypeDict['types'][meais[0]][
                            'text']):  # What is the percentage of noise polluted areas in placename0
                            # field -> field covamount
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        else:
                            # What is the percentage of vacant houses to the house totals in Tarrant County, Texas
                            # 'What is the density of parks in Amsterdam'
                            obj_loc = [coreTypeDict['types'][meais[0]]['text'].index(i) for i in
                                       coreTypeDict['types'][meais[0]]['text'] if 'object' in i]
                            if obj_loc:
                                # obj -> amount
                                trans_obj = {}
                                trans_obj['before'] = [coreTypeDict['types'][meais[0]]['id'][obj_loc[0]]]
                                trans_obj['after'] = [str(core_id)]
                                trans_obj['key'] = coreConTrans['extent'][0]
                                coretrans.append(trans_obj)
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'amount', 'id': str(core_id), 'keyword': '',
                                     'measureLevel': 'era'})
                                coreTypeDict['types'][meais[0]]['id'][obj_loc[0]] = trans_obj['after'][0]
                        # proportion
                        if len(amount_id) == 2:
                            transcross = {}
                            transcross['before'] = coreTypeDict['types'][meais[0]]['id'][0:-1]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            transcross['key'] = coreConTrans['extent'][0]
                            coretrans.append(transcross)
                        elif len(amount_id) == 1:
                            transcross = {}
                            transcross['before'] = [str(core_id), trans_ext['after'][0]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            transcross['key'] = coreConTrans['extent'][0]
                            coretrans.append(transcross)
                            core_id += 1
                    elif supis and con_meais:
                        # object* condi = object_u or field * condi = field_u  or objconA * condi = objconA_u
                        # What is the proportion of noise larger than 70 db for each neighbourhood in Amsterdam
                        if 'compareR' in coreTypeDict['types'][con_meais[0]]['tag'] and len(
                                coreTypeDict['types'][con_meais[0]]['tag']) == 1:
                            compR_trans = {}
                            compR_trans['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                            compR_trans['after'] = [str(core_id)]
                            coretrans.append(compR_trans)
                        else:  # percentage of households within 2000 meters from the supermarkets for each district
                            transcross_condi = {}
                            transcross_condi['before'] = [coreTypeDict['types'][con_meais[0]]['id'][-1],
                                                          coreTypeDict['types'][meais[0]]['id'][0]]
                            transcross_condi['after'] = [str(core_id)]
                            coretrans.append(transcross_condi)
                        newtype = new_type(coreTypeDict['types'][meais[0]]['id'][0])
                        coreConTrans.setdefault('types', []).append(newtype)
                        core_id += 1
                        # object_u * support -> object_u amount or field_u * support -> field_u covamount, key required
                        transcross = {}
                        transcross['before'] = [newtype['id'], coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                        if newtype['type'] == 'object':
                            coreConTrans.setdefault('types', []).append(
                                {'type': 'amount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        elif newtype['type'] == 'field':
                            coreConTrans.setdefault('types', []).append(
                                {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        else:
                            coreConTrans.setdefault('types',[]).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        core_id += 1
                        # object * support = object_u_u amount  key required
                        if mea1is:
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][mea1is[0]]['id'][0],coreTypeDict['types'][supis[0]]['id'][-1]]
                            transcross['after'] = [str(core_id)]
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][mea1is[0]]['id'][0]))
                        else:
                            if newtype['type'] == 'object' or "amount" in newtype['type']:
                                transcross_sup = {}
                                transcross_sup['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross_sup['after'] = [str(core_id)]
                                transcross_sup['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'amount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                            elif newtype['type'] == 'field':  # support -> covamount if field,
                                transcross_sup = {}
                                transcross_sup['before'] = [coreTypeDict['types'][supis[0]]['id'][-1]]
                                transcross_sup['after'] = [str(core_id)]
                                coreConTrans.setdefault('types', []).append(
                                    {'type': 'covamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                            coretrans.append(transcross_sup)
                        # object_u amount * object_u_u amount -> proportion or field_u covamount * field_u_u covamount -> proportion
                        transcross_pro = {}
                        transcross_pro['before'] = [str(core_id - 1), str(core_id)]
                        transcross_pro['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        transcross_pro['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross_pro)
                        core_id += 1
                else:  # only one proportion in measure. e.g.,What is the crime density within the buffer area of the shortest path from home to workplace in Amsterdam
                    if con_meais and not supis:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][con_meais[0]]['id'][-1],
                                                coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [str(core_id)]
                        if 'distfield' in coreTypeDict['types'][0]['tag']:
                            dist_index = [i for i, j in enumerate(coreConTrans['types']) if j['type'] == 'distfield'][0]
                            if coreTypeDict['types'][0]['tag'][dist_index - 1] == 'networkC':
                                transcross['key'] = str(core_id - 1)
                            elif coreTypeDict['types'][0]['tag'][dist_index - 1] == 'coreC':
                                transcross['key'] = coreTypeDict['types'][0]['id'][dist_index - 1]
                        coretrans.append(transcross)
                        # add new proportion type in coreConTrans[types]
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        core_id += 1
                    elif supis and not con_meais:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][supis[0]]['id'][-1],
                                                coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [str(core_id)]
                        transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        core_id += 1
            elif any('objconobjconpro' in e for e in coreTypeDict['types'][meais[0]]['text']) and any(
                    'object' in e for e in coreTypeDict['types'][meais[0]]['text']):
                if supis and not con_meais:
                    # object/objconA * support - > objconA
                    trans_sup = {}
                    trans_sup['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                           coreTypeDict['types'][supis[0]]['id'][0]]
                    trans_sup['after'] = [str(core_id)]
                    trans_sup['key'] = coreTypeDict['types'][supis[0]]['id'][0]
                    coretrans.append(trans_sup)
                    coreConTrans.setdefault('types', []).append(
                        {'type': 'objconamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                    core_id += 1
                    # objconA * a unknown objconA -> proportion
                    transcross = {}
                    transcross['before'] = [trans_sup['after'][0], str(core_id)]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    transcross['key'] = coreTypeDict['types'][supis[0]]['id'][0]
                    coretrans.append(transcross)
                    coreConTrans.setdefault('types', []).append(
                        {'type': 'objconamount', 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                    core_id += 1
            elif any('conamount' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                    'aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']) and not any(
                'proportion' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                'covamount' in e for e in coreTypeDict['types'][meais[0]]['text']):
                if supis and not con_meais:
                    if len(coreTypeDict['types'][meais[0]]['tag']) == 2:  # conamount of coreC
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                    else:  # What is the WOZ-waarde for each neighborhood in Amsterdam, What is the population for each city in Aichi prefecture in Japan
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                elif con_meais and not supis:
                    if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                        # object * condition -> object_u
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][con_meais[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        transcross = {}
                        transcross['before'] = [str(core_id)]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        transcross['key'] = coreConTrans['extent'][0]
                        coretrans.append(transcross)
                        core_id += 1
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][con_meais[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        transcross['key'] = coreConTrans['extent'][0]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        core_id += 1
                elif con_meais and supis:
                    for ci in con_meais:
                        if len(coreTypeDict['types'][ci]['tag']) == 1 and (
                                coreTypeDict['types'][ci]['tag'][0] == 'extremaR' or coreTypeDict['types'][ci]['tag'][
                            0] == 'compareR'):
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                            coreTypeDict['types'][meais[0]]['id'][0] = transcross['after'][0]
                            core_id += 1
                        else:
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                    coreTypeDict['types'][ci]['id'][-1]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                            coreTypeDict['types'][meais[0]]['id'][0] = transcross['after'][0]
                            core_id += 1
                    if len(coreTypeDict['types'][meais[0]]['tag']) == 2:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                elif not con_meais and not supis:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    transcross['key'] = coreConTrans['extent'][0]
                    coretrans.append(transcross)
            elif any('covamount' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                    'aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']):
                if not supis and not con_meais:
                    if 'loc' in coreTypeDict['types'][meais[0]]['text'][-1] and 'weight' in coreTypeDict:
                        if coreTypeDict[
                            'weight'] == 2:  # What is the mean center of customers weighted by the number of transactions in Oleander city
                            # transformation within weight
                            trans_weight = {}
                            trans_weight['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                            trans_weight['after'] = [coreTypeDict['types'][meais[0]]['id'][1]]
                            if 'conamount' in coreTypeDict['types'][meais[0]]['text'][1]:
                                trans_weight['key'] = coreTypeDict['types'][meais[0]]['id'][2]
                            coretrans.append(trans_weight)
                            # weight output * measure input -> covamount loc
                            transcross = {}
                            transcross['before'] = coreTypeDict['types'][meais[0]]['id'][1:3]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                        elif coreTypeDict[
                            'weight'] == 1:  # What is the mean center of the fire calls weighted by the priority in Fort Worth
                            # weight * measure input -> covamount loc
                            transcross = {}
                            transcross['before'] = coreTypeDict['types'][meais[0]]['id'][0:2]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                    else:
                        print('else')
                        cov_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                        # if 'era' in coreTypeDict['types'][meais[0]]['text'][-1].split(' '):  # is key required? no
                        #     cov_trans[0]['key'] = coreConTrans['extent'][0]
                        coretrans.extend(cov_trans)
                elif supis and not con_meais:
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        coretrans.append(transcross)
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        if 'era' in coreTypeDict['types'][meais[0]]['text'][-1].split(' '):  # is key required? no
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                elif con_meais and not supis:
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][conis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        coretrans.append(transcross)
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][conis[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        transcross = {}
                        transcross['before'] = [str(core_id)]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                        core_id += 1
                elif supis and con_meais:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][1]]
                    coretrans.append(transcross)
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
            elif any('aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']):
                if len(coreTypeDict['types'][meais[0]]['tag']) - 1 > 1:
                    befagg_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                    coretrans.extend(befagg_trans)
                    if 'extreDist' in coreTypeDict['types'][0]['tag']:
                        extre_index = coreTypeDict['types'][0]['tag'].index('extreDist')
                        coreTypeDict['types'][0]['id'].insert(extre_index, str(core_id - 1))
                if supis:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2],
                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                    coretrans.append(transcross)
                # TODO: update later, if extreDist exsit
                elif con_meais:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2],
                                            coreTypeDict['types'][con_meais[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    coretrans.append(transcross)
                else:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    transcross['key'] = coreTypeDict['types'][coreTypeDict['funcRole'].index('extent')][0]
                    coretrans.append(transcross)
            else:
                if supis and not con_meais:
                    if len(coreTypeDict['types'][meais[0]]['id']) == 1:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        if 'quality' in coreTypeDict['types'][meais[0]]['text'][0]:
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        core_id += 1
                    # -------new--------
                    elif len(coreTypeDict['types'][meais[0]]['id'][0]) > 1:
                        mea_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                        if 'quality' in coreTypeDict['types'][meais[0]]['text'][-1]:
                            mea_trans[-1]['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.extend(mea_trans)
                    # -------new--------
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        if 'quality' in coreTypeDict['types'][meais[0]]['text'][-1]:
                            transcross['key'] = coreTypeDict['types'][supis[0]]['id'][-1]
                        coretrans.append(transcross)
                elif con_meais and not supis:
                    for ci in con_meais:
                        if len(coreTypeDict['types'][ci]['tag']) == 1 and (
                                coreTypeDict['types'][ci]['tag'][0] == 'extremaR' or coreTypeDict['types'][ci]['tag'][
                            0] == 'compareR'):
                            transcross = {}
                            if type(coreTypeDict['types'][meais[0]]['id'][0]) is list:
                                # What is the network distance to primary schools for children aged between 4 and 12 in Multifunctional Urban Area in Rotterdam
                                trans_bef_id = coreTypeDict['types'][meais[0]]['id'][0][0]
                            else:
                                trans_bef_id = coreTypeDict['types'][meais[0]]['id'][0]
                            transcross['before'] = [trans_bef_id]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(
                                new_type(trans_bef_id))
                            core_id += 1
                        # elif len(coreTypeDict['types'][ci]['tag']) == 2 and coreTypeDict['types'][meais[0]]['tag'][0] != 'location':
                        #     # and (coreTypeDict['types'][ci]['tag'][0] == 'extremaR' or coreTypeDict['types'][ci]['tag'][0] == 'compareR')
                        #     trans_compR = {}
                        #     trans_compR['before'] = [coreTypeDict['types'][ci]['id'][0]]
                        #     trans_compR['after'] = [str(core_id)]
                        #     coretrans.append(trans_compR)
                        #     coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][ci]['id'][0]))
                        #     core_id += 1
                        #     transcross = {}
                        #     transcross['before'] = [trans_compR['after'][0], coreTypeDict['types'][meais[0]]['id'][0]]
                        #     transcross['after'] = [str(core_id)]
                        #     coretrans.append(transcross)
                        #     coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        #     core_id += 1
                        elif coreTypeDict['types'][meais[0]]['tag'][0] == 'location' or \
                                coreTypeDict['types'][meais[0]]['tag'][0] == 'allocation':
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][ci]['id'][-1]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                        else:  # What houses are for sale and in neighborhoods with crime rate lower than 50 per 1000 people in Utrecht
                            transcross = {}
                            if type(coreTypeDict['types'][meais[0]]['id'][0]) is list:
                                transbef_id = coreTypeDict['types'][meais[0]]['id'][0][0]
                            else:
                                transbef_id= coreTypeDict['types'][meais[0]]['id'][0]
                            transcross['before'] = [transbef_id, coreTypeDict['types'][ci]['id'][-1]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(new_type(transbef_id))
                            core_id += 1
                        # How many buildings are within 3 minutes of driving time from fire stations in Oleander
                        # Where are the flat areas within 500 meters of a major highway in the United Kingdom
                        if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                            if type(coreTypeDict['types'][meais[0]]['id'][0]) is list:
                                # What is the potential geographic access from communities to the sexual and productive health services located in rural areas
                                coreTypeDict['types'][meais[0]]['id'][0][0] = transcross['after'][0]
                            else:
                                coreTypeDict['types'][meais[0]]['id'][0] = transcross['after'][0]
                            mea_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                            if coreTypeDict['types'][meais[0]]['tag'][-1] == "conAm":
                                mea_trans[0]['key'] = coreConTrans['extent'][0]
                            # if len(con_meais) > 1:
                            #     mea_trans[-1]['after'][0] = mea_trans[-1]['after'][0] + sign
                            coretrans.extend(mea_trans)
                            mc.append(mea_trans[-1]['after'][0])
                        else:
                            mc.append(transcross['after'][0])
                    if len(mc) > 1:
                        transcross = {}
                        transcross['before'] = mc
                        transcross['after'] = [str(core_id)]
                        coretrans.append(transcross)
                        coreConTrans.setdefault('types', []).append(new_type(mc[0]))
                        core_id += 1
                else:
                    if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                        if 'extreDist' in result['parseTreeStr'] and not (any('network' in e for e in coreTypeDict['types'][meais[0]]['tag']) or any('destination' in e for e in coreTypeDict['types'][meais[0]]['tag'])):
                            transcross = {}
                            transcross['before'] = coreTypeDict['types'][meais[0]]['id']
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][-1]))
                        else:
                            mea_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                            # -----new-------
                            if coreTypeDict['types'][meais[0]]['tag'][-1] == "conAm":
                                mea_trans[0]['key'] = coreConTrans['extent'][0]
                            # -----new-------
                            coretrans.extend(mea_trans)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [str(core_id)]
                        coreConTrans.setdefault('types', []).append(new_type(coreTypeDict['types'][meais[0]]['id'][0]))
                        coretrans.append(transcross)

        coreConTrans.setdefault('transformations', []).extend(coretrans)

        print(coreConTrans)

    except:
        coreConTrans['transformations'] = []

    return coreConTrans


if __name__ == '__main__':
    results = []
    nlp_en = CustomEnglish()  # [X] Load English stopwords
    nlp = en_core_web_sm.load()  # load en_core_web_sm of English for NER, noun chunks
    matcher = PhraseMatcher(nlp.vocab)  # add noun phrases when doing noun_chunks
    patterns = [nlp('bus stops'), nlp('driving time'), nlp('grid cell'), nlp('grid cells'), nlp('off street paths'),
                nlp('mean direction'), nlp('degree of clustering'), nlp('degree of dispersion'), nlp('fire call'),
                nlp('fire calls'), nlp('slope'), nlp('wetlands'), nlp('house totals'), nlp('fire hydrant'),
                nlp('fire scene'), nlp('fire scenes'), nlp('walkability'), nlp('owner occupied houses'),
                nlp('temperature in celsius'), nlp('police beat'), nlp('police beats'), nlp('mean center'),
                nlp('tornado touchdowns'), nlp('nurse practitioner services'), nlp('priority rankings'),
                nlp('tram stations'), nlp('tram station'), nlp('plumbing'), nlp('political leaning'),
                nlp('predicted probability surface'), nlp('fire accidents'), nlp('for sale'), nlp('open at'),
                nlp('predicted distribution probability'), nlp('senior high schools'), nlp('floodplain'),
                nlp('income of households'), nlp('interpolated surface'), nlp('average cost per acre'),
                nlp('high school students'), nlp('wind farm proposals'), nlp('planned commercial district'),
                nlp('protected region'), nlp('pc4 area'), nlp('aspect'), nlp('monthly rainfall'),
                nlp('hot spots and cold spots'), nlp('ski pistes'), nlp('outpatient services'),
                nlp('per household online loan application rates'), nlp('windsurfing spot'), nlp('accident'),
                nlp('census tract'), nlp('mean annual PM 2.5 concentration'), nlp('PM 2.5 concentration'),
                nlp('cesium 137 concentration'), nlp('aquifer')]
    # phrases missed by noun_chunks, add manually
    # [nlp('911 calls'), nlp('precinct'), nlp('forest areas'), nlp('flower stores'), nlp('alarm territory'), nlp('airport')]
    matcher.add("PHRASES", patterns)

    predictorELMo = Predictor.from_path(
        "https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz")  # Allennlp Elmo-based NER

    # [X] Read question file
    questionFilepath = 'corpus.txt'
    errorQuestionFilePath = 'error.txt'
    error_ques = open(errorQuestionFilePath, 'w+')

    afterplace = 'afterplace.txt'
    ap = open(afterplace, 'w+')
    afterentity = 'afterentity.txt'
    ae = open(afterentity, 'w+')
    afterconcept = 'afterconcept.txt'
    ac = open(afterconcept, 'w+')
    afterparser = 'afterparser.txt'
    apar = open(afterparser, 'w+')

    # [X] Read place type set
    ptypePath = 'Dictionary/place_type.txt'
    pt_set = set(line.strip() for line in open(ptypePath, encoding="utf-8"))

    # [X] Read core concept dictionary
    corePath = 'Dictionary/coreConceptsML.txt'
    coreCon_dict = load_ccdict(corePath)
    networkPath = 'Dictionary/network.txt'
    networkSet = set(l.strip() for l in open(networkPath, encoding="utf-8"))

    pos = []
    units = {'db', 'dB', 'decibel', 'meters'}
    # distWords = {'meter', 'meters', 'km', 'kilometers', 'kilometer', 'mile', 'miles'}
    humanWords = {'people', 'population', 'children'}
    amsign = {'have', 'has', 'had', 'no'}
    compR = ['lower than', 'larger than', 'at least', 'less than', 'more than', 'greater than',
             'greater than or equal to', 'smaller than', 'equal to']
    cn = {'least cost route', 'least cost path', 'least costly route', 'least costly path', 'driving time',
          'high school students', 'senior high schools',
          'travel time', 'forest areas', 'for sale', 'open at', 'shortest network based paths', 'tram station',
          'tram stations', 'senior high school district',
          'hot spots and cold spots', 'shortest path', 'cesium 137 concentration', 'PM2.5 concentration',
          'potentially deforested areas'}
    removeWords = {'what', 'where', 'which', 'how', 'for', 'each', 'when', 'who', 'why', 'new', 'no', 'similar',
                   'nearest', 'most', 'to', 'at', 'low', 'high', 'aged'}
    que_stru = {'measure', 'measure1', 'condition', 'subcon', 'support'}
    measLevel = {'interval', 'nominal', 'ratio', 'count', 'loc', 'ordinal', 'era', 'ira', 'boolean'}

    with open(questionFilepath, encoding="utf-8") as questions:
        for question in questions:
            try:
                result = {}
                core_id = 0
                coreConTrans = {}  # final cctrans output
                measureType = {}
                sym = '" ? \n \t'
                result['question'] = question.strip(sym)
                print('---------Question---------')
                print(question)

                # [X] Tokenization
                doc = nlp_en(result['question'])

                # [X] Cleaning text: remove stopwords and save the tokens in a list
                # text = ' '.join([word for word in text if word not in string.punctuation])
                token_list = []
                for word in doc:
                    if not word.is_stop and not word.is_punct or word.text == ',':
                        token_list.append(word)
                sen = ' '.join(word.text for word in token_list).strip()  # Question in string without stopwords
                sen_Clean = word2num(sen)  # Convert numeric words into digit numbers
                result['cleaned_Question'] = sen_Clean

                # XIdentify place names
                re_Place = place_ner(sen_Clean)
                result['placename'] = re_Place[0]  # re_Place[0]: list - PlaceName

                # [X] Identify Date, Time, Quantity, Cardinal, Percent
                re_Entities = entity_ner(re_Place[1])  # parsed_Place[1]: sentence
                result.update(re_Entities[0])  # parsed_Entities[0]: dictionary - Time, Quantity, Percent, Date

                # [X] Identify Core Concept
                re_CoreCon = core_concept_match(re_Entities[1].lower())  # parsed_Entities[1]: sentence
                result.update(re_CoreCon[0])  # re_CoreCon[0]: dictionary - Core Concepts
                result['ner_Question'] = re_CoreCon[1]  # re_CoreCon[1] : sentence with core concepts holders

                #print(result)

                # [X] Generate parser tree & Extract core concept transformation
                parsedQuestion = geo_parser(re_CoreCon[1])
                if parsedQuestion[0]:
                    result['parseTreeStr'] = parsedQuestion[0]
                if parsedQuestion[2]:
                    error_ques.write(parsedQuestion[3] + '\n')  # questions can not be parsed in the grammar
                if parsedQuestion[1] and coreConTrans:
                    result['cctrans'] = write_trans(parsedQuestion[1])

                print(result)

                ap.write(re_Place[1] + '\n')
                ae.write(re_Entities[1] + '\n')
                ac.write(re_CoreCon[1] + '\n')
                if parsedQuestion[0]:
                    apar.write(parsedQuestion[0] + '\n')

                results.append(result)
            except:
                ques_incorrect = question
                apar.write(ques_incorrect + '\n')

    # with open('Results_test_Auto.json', 'w') as outputFile:
    #     json.dump(results, outputFile)

    with open('parse results.json', 'w') as outputFile:
        json.dump(results, outputFile)

    error_ques.close()
    ap.close()
    ae.close()
    ac.close()
    apar.close()
